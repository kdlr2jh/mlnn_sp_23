{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Image Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as  plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Neural Network\n",
    "Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1663deee0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZgUlEQVR4nO3df2zU953n8ddgYGLQMCuX2DNTHK+Vg2uFEd0CBXz8MGywmFVQiBMtSXQ9I7UoaQwn5ETZUnaFryvhLBUs0rqhapqloEJBJxGCBBviHNgUEboOIhsvTZGzmOAsnrr4Eo8xZBzgc3/4mN3BBvI1M3577OdD+krxzPfDvPPtV33yzcx87XPOOQEAYGCM9QAAgNGLCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNjrQe4061bt3T58mUFAgH5fD7rcQAAHjnn1N3drUgkojFj7n2tM+widPnyZRUWFlqPAQB4QG1tbZoyZco99xl2EQoEApKkBfoLjdU442kAAF7d0Jc6qSPJ/z+/l4xF6LXXXtNPfvITtbe3a/r06dq+fbsWLlx433W3/xPcWI3TWB8RAoCs8//vSPpV3lLJyAcT9u/fr/Xr12vjxo06e/asFi5cqGg0qkuXLmXi5QAAWSojEdq2bZu+973v6fvf/76++c1vavv27SosLNSOHTsy8XIAgCyV9gj19vbqzJkzKi8vT3m8vLxcp06d6rd/IpFQPB5P2QAAo0PaI3TlyhXdvHlTBQUFKY8XFBQoFov127+2tlbBYDC58ck4ABg9MvZl1TvfkHLODfgm1YYNG9TV1ZXc2traMjUSAGCYSfun4yZPnqycnJx+Vz0dHR39ro4kye/3y+/3p3sMAEAWSPuV0Pjx4zVr1izV19enPF5fX6/S0tJ0vxwAIItl5HtC1dXV+u53v6vZs2dr/vz5+vnPf65Lly7phRdeyMTLAQCyVEYitGrVKnV2durHP/6x2tvbVVJSoiNHjqioqCgTLwcAyFI+55yzHuI/i8fjCgaDKtMT3DEBALLQDfelGvSWurq6NGnSpHvuy69yAACYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMyMtR4AALzoeXqu5zV/t2XHoF7rb//yf3he497/10G91mjFlRAAwAwRAgCYSXuEampq5PP5UrZQKJTulwEAjAAZeU9o+vTpevfdd5M/5+TkZOJlAABZLiMRGjt2LFc/AID7ysh7Qi0tLYpEIiouLtYzzzyjCxcu3HXfRCKheDyesgEARoe0R2ju3LnavXu3jh49qtdff12xWEylpaXq7OwccP/a2loFg8HkVlhYmO6RAADDVNojFI1G9dRTT2nGjBl67LHHdPjwYUnSrl27Btx/w4YN6urqSm5tbW3pHgkAMExl/MuqEydO1IwZM9TS0jLg836/X36/P9NjAACGoYx/TyiRSOijjz5SOBzO9EsBALJM2iP08ssvq7GxUa2trfrtb3+rp59+WvF4XJWVlel+KQBAlkv7f4779NNP9eyzz+rKlSt6+OGHNW/ePJ0+fVpFRUXpfikAQJZLe4T27duX7j9yRLj+xHe8r/ma9y/55v3je57XANmkY7b3/4DztxdXZGASpAP3jgMAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzGT8l9qhz+VF3ns/4dHPvb/QP3pfApgZ4/0mve6R657X/Hn+7z2vkaT/4ysd1Dp8dVwJAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAx30R4i/+vx/+15zd99VJ6BSYDhI+fRIs9rfr/Y+63iv/XP/93zGkmKNDUPah2+Oq6EAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAz3MB0iIzz3bAeARh2xv7i2pC8zvV/mzQkrwPvuBICAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMxwA9NBuLXgW57XLHzoZPoHAbLcn07sHJLXKXz35pC8DrzjSggAYIYIAQDMeI7QiRMntGLFCkUiEfl8Ph08eDDleeecampqFIlElJubq7KyMp07dy5d8wIARhDPEerp6dHMmTNVV1c34PNbtmzRtm3bVFdXp6amJoVCIS1btkzd3d0PPCwAYGTx/MGEaDSqaDQ64HPOOW3fvl0bN25URUWFJGnXrl0qKCjQ3r179fzzzz/YtACAESWt7wm1trYqFoupvLw8+Zjf79fixYt16tSpAdckEgnF4/GUDQAwOqQ1QrFYTJJUUFCQ8nhBQUHyuTvV1tYqGAwmt8LCwnSOBAAYxjLy6Tifz5fys3Ou32O3bdiwQV1dXcmtra0tEyMBAIahtH5ZNRQKSeq7IgqHw8nHOzo6+l0d3eb3++X3+9M5BgAgS6T1Sqi4uFihUEj19fXJx3p7e9XY2KjS0tJ0vhQAYATwfCV09epVffzxx8mfW1tb9cEHHygvL0+PPPKI1q9fr82bN2vq1KmaOnWqNm/erAkTJui5555L6+AAgOznOULvv/++lixZkvy5urpaklRZWalf/vKXeuWVV3T9+nW9+OKL+uyzzzR37ly98847CgQC6ZsaADAieI5QWVmZnHN3fd7n86mmpkY1NTUPMtew9snjuZ7X5OdMyMAkwPAx9k8f8bzm6bxDGZikv9zWzwa1jtueZh73jgMAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAICZtP5m1dFi7H/pHpLX+eL3fzIkrwOkQ9v2iZ7X/Df/Lc9r3ohP8bxGn8e9r8GQ4EoIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADDDDUyHsfz3vd/cESNXzuSveV7zh6emDeq18v7yU89rGqe9MYhXesjzih0/Xel5Tf4fTnleg6HBlRAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYbmA5j1/O8/x1hYgbmSKdbC//M8xqX4/O8pu0xv+c1ktQb+dLzmjHjb3pe887Cf/C8Zpz3w6DYzcEdh7+58KTnNf/3lvcb7k4Y4/3YFfy22/Ma53kFhgpXQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGW5gOgiJL8Z5XnNrELdQ3Pmjv/e85tDab3leM5T+6mu/8LxmjLzfufO66/W8RpIu3/R+Q826P5Z5XvPYu+s9r/mTs+M9rwm/8wfPayTJ98mnntf88aNcz2sKcrzfMNY1NXteg+GLKyEAgBkiBAAw4zlCJ06c0IoVKxSJROTz+XTw4MGU51evXi2fz5eyzZs3L13zAgBGEM8R6unp0cyZM1VXV3fXfZYvX6729vbkduTIkQcaEgAwMnn+YEI0GlU0Gr3nPn6/X6FQaNBDAQBGh4y8J9TQ0KD8/HxNmzZNa9asUUdHx133TSQSisfjKRsAYHRIe4Si0aj27NmjY8eOaevWrWpqatLSpUuVSCQG3L+2tlbBYDC5FRYWpnskAMAwlfbvCa1atSr5zyUlJZo9e7aKiop0+PBhVVRU9Nt/w4YNqq6uTv4cj8cJEQCMEhn/smo4HFZRUZFaWloGfN7v98vv92d6DADAMJTx7wl1dnaqra1N4XA40y8FAMgynq+Erl69qo8//jj5c2trqz744APl5eUpLy9PNTU1euqppxQOh3Xx4kX96Ec/0uTJk/Xkk0+mdXAAQPbzHKH3339fS5YsSf58+/2cyspK7dixQ83Nzdq9e7c+//xzhcNhLVmyRPv371cgEEjf1ACAEcHnnPN+Z80MisfjCgaDKtMTGuvzfqPQ4aq1dr7nNYVz/j0Dk2SfP/7TFM9rvnbO+40xJWn8202DWjfS/PtflXpe8y//8+5fYL+bfVcf9rxm93/lg0vD3Q33pRr0lrq6ujRp0qR77su94wAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGAm479ZFX2KN7xnPULWCuuS9QijzoRFfxyS1/nr4095XjNN/5yBSWCFKyEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAw3MAVgpugtZz0CjHElBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwM9Z6AAAjQ47P+99pP5s2zvOa0D95XoJhjCshAIAZIgQAMOMpQrW1tZozZ44CgYDy8/O1cuVKnT9/PmUf55xqamoUiUSUm5ursrIynTt3Lq1DAwBGBk8RamxsVFVVlU6fPq36+nrduHFD5eXl6unpSe6zZcsWbdu2TXV1dWpqalIoFNKyZcvU3d2d9uEBANnN0wcT3n777ZSfd+7cqfz8fJ05c0aLFi2Sc07bt2/Xxo0bVVFRIUnatWuXCgoKtHfvXj3//PPpmxwAkPUe6D2hrq4uSVJeXp4kqbW1VbFYTOXl5cl9/H6/Fi9erFOnTg34ZyQSCcXj8ZQNADA6DDpCzjlVV1drwYIFKikpkSTFYjFJUkFBQcq+BQUFyefuVFtbq2AwmNwKCwsHOxIAIMsMOkJr167Vhx9+qF//+tf9nvP5fCk/O+f6PXbbhg0b1NXVldza2toGOxIAIMsM6suq69at06FDh3TixAlNmTIl+XgoFJLUd0UUDoeTj3d0dPS7OrrN7/fL7/cPZgwAQJbzdCXknNPatWt14MABHTt2TMXFxSnPFxcXKxQKqb6+PvlYb2+vGhsbVVpamp6JAQAjhqcroaqqKu3du1dvvfWWAoFA8n2eYDCo3Nxc+Xw+rV+/Xps3b9bUqVM1depUbd68WRMmTNBzzz2XkX8BAED28hShHTt2SJLKyspSHt+5c6dWr14tSXrllVd0/fp1vfjii/rss880d+5cvfPOOwoEAmkZGAAwcniKkHPuvvv4fD7V1NSopqZmsDMByEI33S3vi7hx2KjHKQAAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzg/rNqgCQDtfmXLMeAca4EgIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzHADUwBpkePj77TwjrMGAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADDDDUwB9JN492HPa25+61YGJsFIx5UQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGDG55xz1kP8Z/F4XMFgUGV6QmN946zHAQB4dMN9qQa9pa6uLk2aNOme+3IlBAAwQ4QAAGY8Rai2tlZz5sxRIBBQfn6+Vq5cqfPnz6fss3r1avl8vpRt3rx5aR0aADAyeIpQY2OjqqqqdPr0adXX1+vGjRsqLy9XT09Pyn7Lly9Xe3t7cjty5EhahwYAjAyefrPq22+/nfLzzp07lZ+frzNnzmjRokXJx/1+v0KhUHomBACMWA/0nlBXV5ckKS8vL+XxhoYG5efna9q0aVqzZo06Ojru+mckEgnF4/GUDQAwOgw6Qs45VVdXa8GCBSopKUk+Ho1GtWfPHh07dkxbt25VU1OTli5dqkQiMeCfU1tbq2AwmNwKCwsHOxIAIMsM+ntCVVVVOnz4sE6ePKkpU6bcdb/29nYVFRVp3759qqio6Pd8IpFICVQ8HldhYSHfEwKALOXle0Ke3hO6bd26dTp06JBOnDhxzwBJUjgcVlFRkVpaWgZ83u/3y+/3D2YMAECW8xQh55zWrVunN998Uw0NDSouLr7vms7OTrW1tSkcDg96SADAyOTpPaGqqir96le/0t69exUIBBSLxRSLxXT9+nVJ0tWrV/Xyyy/rvffe08WLF9XQ0KAVK1Zo8uTJevLJJzPyLwAAyF6eroR27NghSSorK0t5fOfOnVq9erVycnLU3Nys3bt36/PPP1c4HNaSJUu0f/9+BQKBtA0NABgZPP/nuHvJzc3V0aNHH2ggAMDowb3jAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmxloPcCfnnCTphr6UnPEwAADPbuhLSf/x/+f3Muwi1N3dLUk6qSPGkwAAHkR3d7eCweA99/G5r5KqIXTr1i1dvnxZgUBAPp8v5bl4PK7CwkK1tbVp0qRJRhPa4zj04Tj04Tj04Tj0GQ7HwTmn7u5uRSIRjRlz73d9ht2V0JgxYzRlypR77jNp0qRRfZLdxnHow3How3How3HoY30c7ncFdBsfTAAAmCFCAAAzWRUhv9+vTZs2ye/3W49iiuPQh+PQh+PQh+PQJ9uOw7D7YAIAYPTIqishAMDIQoQAAGaIEADADBECAJjJqgi99tprKi4u1kMPPaRZs2bpN7/5jfVIQ6qmpkY+ny9lC4VC1mNl3IkTJ7RixQpFIhH5fD4dPHgw5XnnnGpqahSJRJSbm6uysjKdO3fOZtgMut9xWL16db/zY968eTbDZkhtba3mzJmjQCCg/Px8rVy5UufPn0/ZZzScD1/lOGTL+ZA1Edq/f7/Wr1+vjRs36uzZs1q4cKGi0aguXbpkPdqQmj59utrb25Nbc3Oz9UgZ19PTo5kzZ6qurm7A57ds2aJt27aprq5OTU1NCoVCWrZsWfI+hCPF/Y6DJC1fvjzl/DhyZGTdg7GxsVFVVVU6ffq06uvrdePGDZWXl6unpye5z2g4H77KcZCy5HxwWeI73/mOe+GFF1Ie+8Y3vuF++MMfGk009DZt2uRmzpxpPYYpSe7NN99M/nzr1i0XCoXcq6++mnzsiy++cMFg0P3sZz8zmHBo3HkcnHOusrLSPfHEEybzWOno6HCSXGNjo3Nu9J4Pdx4H57LnfMiKK6He3l6dOXNG5eXlKY+Xl5fr1KlTRlPZaGlpUSQSUXFxsZ555hlduHDBeiRTra2tisViKeeG3+/X4sWLR925IUkNDQ3Kz8/XtGnTtGbNGnV0dFiPlFFdXV2SpLy8PEmj93y48zjclg3nQ1ZE6MqVK7p586YKCgpSHi8oKFAsFjOaaujNnTtXu3fv1tGjR/X6668rFouptLRUnZ2d1qOZuf2//2g/NyQpGo1qz549OnbsmLZu3aqmpiYtXbpUiUTCerSMcM6purpaCxYsUElJiaTReT4MdByk7Dkfht1dtO/lzl/t4Jzr99hIFo1Gk/88Y8YMzZ8/X48++qh27dql6upqw8nsjfZzQ5JWrVqV/OeSkhLNnj1bRUVFOnz4sCoqKgwny4y1a9fqww8/1MmTJ/s9N5rOh7sdh2w5H7LiSmjy5MnKycnp9zeZjo6Ofn/jGU0mTpyoGTNmqKWlxXoUM7c/Hci50V84HFZRUdGIPD/WrVunQ4cO6fjx4ym/+mW0nQ93Ow4DGa7nQ1ZEaPz48Zo1a5bq6+tTHq+vr1dpaanRVPYSiYQ++ugjhcNh61HMFBcXKxQKpZwbvb29amxsHNXnhiR1dnaqra1tRJ0fzjmtXbtWBw4c0LFjx1RcXJzy/Gg5H+53HAYybM8Hww9FeLJv3z43btw498Ybb7jf/e53bv369W7ixInu4sWL1qMNmZdeesk1NDS4CxcuuNOnT7vHH3/cBQKBEX8Muru73dmzZ93Zs2edJLdt2zZ39uxZ98knnzjnnHv11VddMBh0Bw4ccM3Nze7ZZ5914XDYxeNx48nT617Hobu727300kvu1KlTrrW11R0/ftzNnz/fff3rXx9Rx+EHP/iBCwaDrqGhwbW3tye3a9euJfcZDefD/Y5DNp0PWRMh55z76U9/6oqKitz48ePdt7/97ZSPI44Gq1atcuFw2I0bN85FIhFXUVHhzp07Zz1Wxh0/ftxJ6rdVVlY65/o+lrtp0yYXCoWc3+93ixYtcs3NzbZDZ8C9jsO1a9dceXm5e/jhh924cePcI4884iorK92lS5esx06rgf79JbmdO3cm9xkN58P9jkM2nQ/8KgcAgJmseE8IADAyESEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABm/h+kZZY8IvAKlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.max(x_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
       "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
       "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
       "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
       "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
       "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
       "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
       "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
       "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
       "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
       "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
       "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.np_utils.to_categorical(y_train, num_classes)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 16:57:45.815026: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 16:57:46.889898: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.2436 - accuracy: 0.9252 - val_loss: 0.1193 - val_accuracy: 0.9632\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1040 - accuracy: 0.9680 - val_loss: 0.0907 - val_accuracy: 0.9713\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0738 - accuracy: 0.9778 - val_loss: 0.0852 - val_accuracy: 0.9756\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0576 - accuracy: 0.9822 - val_loss: 0.0705 - val_accuracy: 0.9812\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0511 - accuracy: 0.9848 - val_loss: 0.0783 - val_accuracy: 0.9798\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0439 - accuracy: 0.9864 - val_loss: 0.0750 - val_accuracy: 0.9825\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0394 - accuracy: 0.9883 - val_loss: 0.0927 - val_accuracy: 0.9795\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0333 - accuracy: 0.9898 - val_loss: 0.0886 - val_accuracy: 0.9810\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0306 - accuracy: 0.9908 - val_loss: 0.0798 - val_accuracy: 0.9828\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0288 - accuracy: 0.9916 - val_loss: 0.0887 - val_accuracy: 0.9822\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0269 - accuracy: 0.9925 - val_loss: 0.1016 - val_accuracy: 0.9830\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 0.0932 - val_accuracy: 0.9827\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0236 - accuracy: 0.9935 - val_loss: 0.0975 - val_accuracy: 0.9831\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0209 - accuracy: 0.9943 - val_loss: 0.1175 - val_accuracy: 0.9825\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0219 - accuracy: 0.9942 - val_loss: 0.1061 - val_accuracy: 0.9837\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.1102 - val_accuracy: 0.9840\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.1251 - val_accuracy: 0.9830\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.1213 - val_accuracy: 0.9836\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0181 - accuracy: 0.9952 - val_loss: 0.1175 - val_accuracy: 0.9843\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0172 - accuracy: 0.9956 - val_loss: 0.1291 - val_accuracy: 0.9830\n",
      "Test loss: 0.1290832757949829\n",
      "Test accuracy: 0.9829999804496765\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1744b0460>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1290832757949829, 0.9829999804496765]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv Net\n",
    "Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 2.2896 - accuracy: 0.1326 - val_loss: 2.2649 - val_accuracy: 0.2781\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 49s 104ms/step - loss: 2.2494 - accuracy: 0.2264 - val_loss: 2.2168 - val_accuracy: 0.4445\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 50s 107ms/step - loss: 2.1990 - accuracy: 0.3223 - val_loss: 2.1518 - val_accuracy: 0.5464\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 49s 104ms/step - loss: 2.1291 - accuracy: 0.4000 - val_loss: 2.0597 - val_accuracy: 0.6258\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 51s 108ms/step - loss: 2.0315 - accuracy: 0.4620 - val_loss: 1.9330 - val_accuracy: 0.6648\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 52s 112ms/step - loss: 1.9034 - accuracy: 0.5097 - val_loss: 1.7699 - val_accuracy: 0.6956\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 1.7495 - accuracy: 0.5493 - val_loss: 1.5776 - val_accuracy: 0.7248\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 52s 110ms/step - loss: 1.5836 - accuracy: 0.5868 - val_loss: 1.3801 - val_accuracy: 0.7486\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 50s 107ms/step - loss: 1.4232 - accuracy: 0.6169 - val_loss: 1.1981 - val_accuracy: 0.7730\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 51s 109ms/step - loss: 1.2857 - accuracy: 0.6445 - val_loss: 1.0435 - val_accuracy: 0.7939\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 1.1649 - accuracy: 0.6708 - val_loss: 0.9198 - val_accuracy: 0.8082\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 51s 108ms/step - loss: 1.0734 - accuracy: 0.6880 - val_loss: 0.8248 - val_accuracy: 0.8189\n",
      "Test loss: 0.8248116374015808\n",
      "Test accuracy: 0.8188999891281128\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8248116374015808\n",
      "Test accuracy: 0.8188999891281128\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16313c970>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00712639, 0.01037888, 0.00615095, 0.06925707, 0.01661511,\n",
       "         0.02114039, 0.00331039, 0.79419684, 0.02726349, 0.0445606 ]],\n",
       "       dtype=float32),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test[0:1]), y_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test[0:1] > 0.5).astype(\"int32\"), y_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9c/3ylcvqn54zs1r5tlfz4_znf00000gn/T/ipykernel_87184/2765002490.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "model.predict_classes(x_test[0:1]), y_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

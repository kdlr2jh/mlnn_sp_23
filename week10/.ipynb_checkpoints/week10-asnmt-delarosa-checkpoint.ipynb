{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks image recognition - MultiLayer Perceptron\n",
    "Use both MLNN for the following problem.\n",
    "\n",
    "1. Add random noise (see below on `size parameter` on [`np.random.normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html)) to the images in training and testing. **Make sure each image gets a different noise feature added to it. Inspect by printing out several images. Note - the `size` parameter should match the data. **\n",
    "2. Compare the `accuracy` of train and val after N epochs for MLNN with and without noise. \n",
    "3. Vary the amount of noise by changing the `scale` parameter in `np.random.normal` by a factor. Use `.1, .5, 1.0, 2.0, 4.0` for the `scale` and keep track of the `accuracy` for training and validation and plot these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `np.random.normal`\n",
    "\n",
    "## Parameters\n",
    "\n",
    "### loc\n",
    "\n",
    "Mean (“centre”) of the distribution.\n",
    "\n",
    "### scale\n",
    "\n",
    "Standard deviation (spread or “width”) of the distribution. Must be non-negative.\n",
    "\n",
    "### size\n",
    "\n",
    "Output shape. If the given shape is, e.g., (m, n, k), then m * n * k samples are drawn. If size is None (default), a single value is returned if loc and scale are both scalars. Otherwise, np.broadcast(loc, scale).size samples are drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Image Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as  plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Neural Network\n",
    "Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1693f8b20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-7.79948913e-01,  1.23368444e+00,  1.18619325e+00, ...,\n",
       "         -3.09588456e+00,  8.79397186e-01,  2.64386606e+00],\n",
       "        [ 3.44425596e+00, -1.83854837e+00, -5.60777206e-01, ...,\n",
       "          1.46620834e+00,  1.60091780e+00, -7.36136277e-01],\n",
       "        [ 8.50659444e-01,  3.32752908e+00,  1.36297036e+00, ...,\n",
       "          2.25178274e+00, -1.91876706e+00,  3.81780014e-02],\n",
       "        ...,\n",
       "        [ 3.09065951e+00, -1.64374351e+00,  3.30233858e+00, ...,\n",
       "          1.76345221e+00,  1.41782830e+00, -2.17314706e-02],\n",
       "        [ 3.62941690e+00, -1.23337906e+00,  3.27944643e+00, ...,\n",
       "         -2.32842388e-01,  6.95874447e-01,  2.98230483e+00],\n",
       "        [ 3.62719015e+00, -7.60466677e-01,  7.56155355e-01, ...,\n",
       "         -2.64474639e-01, -1.19693993e+00, -1.03411808e+00]],\n",
       "\n",
       "       [[ 4.52232913e+00,  2.98125330e+00,  3.81803779e+00, ...,\n",
       "          1.64478058e+00, -1.50575204e+00,  2.50094111e+00],\n",
       "        [-1.12936178e+00,  1.53509023e+00,  9.50449750e-01, ...,\n",
       "          1.02629395e+00, -8.34944183e-02,  2.02736477e+00],\n",
       "        [ 8.47776213e-01,  6.77934245e-01,  2.21765895e+00, ...,\n",
       "          3.61098637e+00,  3.60937680e-01, -1.08485482e+00],\n",
       "        ...,\n",
       "        [ 1.05675998e+00,  3.42588966e+00, -5.68938545e-01, ...,\n",
       "          2.48324553e+00,  4.33214264e+00,  3.00600008e+00],\n",
       "        [ 1.33937279e+00, -1.55711315e-01,  3.49336955e+00, ...,\n",
       "          1.05007895e+00,  2.18581986e+00, -6.58624969e-01],\n",
       "        [ 2.25601493e-01,  2.09124111e-01,  1.68106290e+00, ...,\n",
       "          1.65905821e+00,  3.78870576e+00, -1.44694840e+00]],\n",
       "\n",
       "       [[ 1.99811923e+00, -7.07217215e-01,  1.84476316e+00, ...,\n",
       "          2.74641764e+00,  2.23136343e+00,  8.35263052e-01],\n",
       "        [ 4.02754879e+00,  2.93383608e+00,  1.46139198e-01, ...,\n",
       "         -2.28832020e+00,  2.51159726e+00,  2.71285435e-01],\n",
       "        [ 2.99529358e+00, -2.86228474e+00,  1.66296283e-01, ...,\n",
       "          2.84612335e+00,  6.61334482e-01,  3.01841245e+00],\n",
       "        ...,\n",
       "        [ 2.23103951e+00,  1.64274947e+00,  1.03129955e-01, ...,\n",
       "         -1.71961556e+00,  3.33131954e+00,  2.15798762e+00],\n",
       "        [ 3.57784941e+00,  7.97327702e-01,  3.17543017e+00, ...,\n",
       "          3.16254991e+00,  8.48093412e-01, -1.43375576e+00],\n",
       "        [-1.02703307e+00,  7.98481725e-02,  1.37801329e+00, ...,\n",
       "         -2.89484034e+00,  1.88834446e+00,  3.99869748e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.92618240e+00,  1.24181950e+00,  2.12733531e-01, ...,\n",
       "          1.63774815e+00, -6.12542196e-01,  1.03909676e+00],\n",
       "        [ 1.50146197e+00, -6.13260815e-01,  5.93172440e-01, ...,\n",
       "         -3.23627344e-01,  5.18632011e-03,  4.70086796e+00],\n",
       "        [-1.22470998e+00, -7.15203925e-01,  1.70317084e+00, ...,\n",
       "          2.31050330e+00,  8.89203242e-01,  5.68290898e+00],\n",
       "        ...,\n",
       "        [ 8.06315683e-01,  1.12048597e+00, -3.44711421e-01, ...,\n",
       "         -4.65508458e+00,  6.72043821e-02, -1.75069523e-01],\n",
       "        [ 2.35089872e+00,  1.40543469e+00, -8.70636909e-01, ...,\n",
       "          1.59966939e-01,  2.39086042e+00,  2.43408363e+00],\n",
       "        [ 1.67124011e+00,  3.18704595e+00,  9.08009048e-01, ...,\n",
       "          1.93240394e+00,  4.23963246e-01, -3.75309945e-01]],\n",
       "\n",
       "       [[ 2.19102937e-01,  1.41579463e+00,  2.52832293e+00, ...,\n",
       "         -2.05694321e+00,  2.01383857e+00,  2.12870318e+00],\n",
       "        [-3.83192776e-02, -8.90541799e-01,  3.24730038e+00, ...,\n",
       "          3.29440537e+00,  3.90587081e+00,  2.59827658e-01],\n",
       "        [ 1.67064996e+00,  1.55707588e+00,  2.24981771e+00, ...,\n",
       "         -1.08739806e+00,  7.13883076e-01,  3.68077655e+00],\n",
       "        ...,\n",
       "        [ 7.28605387e-01, -1.75987521e+00,  2.77110105e+00, ...,\n",
       "          3.68508728e+00,  2.42989619e+00,  1.56704693e+00],\n",
       "        [ 2.60294323e-01,  1.96213702e+00,  2.29835423e-02, ...,\n",
       "          6.21687283e-01,  1.20859411e+00,  4.06079796e+00],\n",
       "        [ 1.86732671e+00, -1.72887102e+00,  3.52130422e-01, ...,\n",
       "          2.89430082e+00, -2.41748968e+00,  3.35497366e+00]],\n",
       "\n",
       "       [[ 1.04006235e+00,  2.45588599e+00, -6.27381692e-01, ...,\n",
       "         -1.05174341e-01, -1.21604993e+00,  7.86795449e-01],\n",
       "        [ 1.00930445e+00,  1.59144464e+00, -1.55099741e+00, ...,\n",
       "          2.46489402e+00,  1.42526678e+00, -1.19577084e+00],\n",
       "        [ 7.36950979e-01,  1.28195165e+00, -1.26889050e-01, ...,\n",
       "          5.73489135e-01,  7.14139060e-01,  9.80986483e-01],\n",
       "        ...,\n",
       "        [-9.83956044e-01,  2.29355609e+00, -1.93470217e+00, ...,\n",
       "          9.88138731e-01,  2.00585253e+00, -9.76859993e-01],\n",
       "        [ 2.79624134e+00, -3.83236605e+00,  9.38764084e-01, ...,\n",
       "          7.29741115e-02,  1.15547812e+00,  2.01198005e+00],\n",
       "        [-2.57159608e+00,  1.52176494e+00, -2.24536595e+00, ...,\n",
       "          2.46218687e-01, -6.12928453e-01,  2.65669360e-01]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import random\n",
    "\n",
    "x = random.normal(loc=1, scale=2, size=x_train.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-7.79948913e-01,  1.23368444e+00,  1.18619325e+00, ...,\n",
       "         -3.09588456e+00,  8.79397186e-01,  2.64386606e+00],\n",
       "        [ 3.44425596e+00, -1.83854837e+00, -5.60777206e-01, ...,\n",
       "          1.46620834e+00,  1.60091780e+00, -7.36136277e-01],\n",
       "        [ 8.50659444e-01,  3.32752908e+00,  1.36297036e+00, ...,\n",
       "          2.25178274e+00, -1.91876706e+00,  3.81780014e-02],\n",
       "        ...,\n",
       "        [ 3.09065951e+00, -1.64374351e+00,  3.30233858e+00, ...,\n",
       "          1.76345221e+00,  1.41782830e+00, -2.17314706e-02],\n",
       "        [ 3.62941690e+00, -1.23337906e+00,  3.27944643e+00, ...,\n",
       "         -2.32842388e-01,  6.95874447e-01,  2.98230483e+00],\n",
       "        [ 3.62719015e+00, -7.60466677e-01,  7.56155355e-01, ...,\n",
       "         -2.64474639e-01, -1.19693993e+00, -1.03411808e+00]],\n",
       "\n",
       "       [[ 4.52232913e+00,  2.98125330e+00,  3.81803779e+00, ...,\n",
       "          1.64478058e+00, -1.50575204e+00,  2.50094111e+00],\n",
       "        [-1.12936178e+00,  1.53509023e+00,  9.50449750e-01, ...,\n",
       "          1.02629395e+00, -8.34944183e-02,  2.02736477e+00],\n",
       "        [ 8.47776213e-01,  6.77934245e-01,  2.21765895e+00, ...,\n",
       "          3.61098637e+00,  3.60937680e-01, -1.08485482e+00],\n",
       "        ...,\n",
       "        [ 1.05675998e+00,  3.42588966e+00, -5.68938545e-01, ...,\n",
       "          2.48324553e+00,  4.33214264e+00,  3.00600008e+00],\n",
       "        [ 1.33937279e+00, -1.55711315e-01,  3.49336955e+00, ...,\n",
       "          1.05007895e+00,  2.18581986e+00, -6.58624969e-01],\n",
       "        [ 2.25601493e-01,  2.09124111e-01,  1.68106290e+00, ...,\n",
       "          1.65905821e+00,  3.78870576e+00, -1.44694840e+00]],\n",
       "\n",
       "       [[ 1.99811923e+00, -7.07217215e-01,  1.84476316e+00, ...,\n",
       "          2.74641764e+00,  2.23136343e+00,  8.35263052e-01],\n",
       "        [ 4.02754879e+00,  2.93383608e+00,  1.46139198e-01, ...,\n",
       "         -2.28832020e+00,  2.51159726e+00,  2.71285435e-01],\n",
       "        [ 2.99529358e+00, -2.86228474e+00,  1.66296283e-01, ...,\n",
       "          2.84612335e+00,  6.61334482e-01,  3.01841245e+00],\n",
       "        ...,\n",
       "        [ 2.23103951e+00,  1.64274947e+00,  1.03129955e-01, ...,\n",
       "         -1.71961556e+00,  3.33131954e+00,  2.15798762e+00],\n",
       "        [ 3.57784941e+00,  7.97327702e-01,  3.17543017e+00, ...,\n",
       "          3.16254991e+00,  8.48093412e-01, -1.43375576e+00],\n",
       "        [-1.02703307e+00,  7.98481725e-02,  1.37801329e+00, ...,\n",
       "         -2.89484034e+00,  1.88834446e+00,  3.99869748e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.92618240e+00,  1.24181950e+00,  2.12733531e-01, ...,\n",
       "          1.63774815e+00, -6.12542196e-01,  1.03909676e+00],\n",
       "        [ 1.50146197e+00, -6.13260815e-01,  5.93172440e-01, ...,\n",
       "         -3.23627344e-01,  5.18632011e-03,  4.70086796e+00],\n",
       "        [-1.22470998e+00, -7.15203925e-01,  1.70317084e+00, ...,\n",
       "          2.31050330e+00,  8.89203242e-01,  5.68290898e+00],\n",
       "        ...,\n",
       "        [ 8.06315683e-01,  1.12048597e+00, -3.44711421e-01, ...,\n",
       "         -4.65508458e+00,  6.72043821e-02, -1.75069523e-01],\n",
       "        [ 2.35089872e+00,  1.40543469e+00, -8.70636909e-01, ...,\n",
       "          1.59966939e-01,  2.39086042e+00,  2.43408363e+00],\n",
       "        [ 1.67124011e+00,  3.18704595e+00,  9.08009048e-01, ...,\n",
       "          1.93240394e+00,  4.23963246e-01, -3.75309945e-01]],\n",
       "\n",
       "       [[ 2.19102937e-01,  1.41579463e+00,  2.52832293e+00, ...,\n",
       "         -2.05694321e+00,  2.01383857e+00,  2.12870318e+00],\n",
       "        [-3.83192776e-02, -8.90541799e-01,  3.24730038e+00, ...,\n",
       "          3.29440537e+00,  3.90587081e+00,  2.59827658e-01],\n",
       "        [ 1.67064996e+00,  1.55707588e+00,  2.24981771e+00, ...,\n",
       "         -1.08739806e+00,  7.13883076e-01,  3.68077655e+00],\n",
       "        ...,\n",
       "        [ 7.28605387e-01, -1.75987521e+00,  2.77110105e+00, ...,\n",
       "          3.68508728e+00,  2.42989619e+00,  1.56704693e+00],\n",
       "        [ 2.60294323e-01,  1.96213702e+00,  2.29835423e-02, ...,\n",
       "          6.21687283e-01,  1.20859411e+00,  4.06079796e+00],\n",
       "        [ 1.86732671e+00, -1.72887102e+00,  3.52130422e-01, ...,\n",
       "          2.89430082e+00, -2.41748968e+00,  3.35497366e+00]],\n",
       "\n",
       "       [[ 1.04006235e+00,  2.45588599e+00, -6.27381692e-01, ...,\n",
       "         -1.05174341e-01, -1.21604993e+00,  7.86795449e-01],\n",
       "        [ 1.00930445e+00,  1.59144464e+00, -1.55099741e+00, ...,\n",
       "          2.46489402e+00,  1.42526678e+00, -1.19577084e+00],\n",
       "        [ 7.36950979e-01,  1.28195165e+00, -1.26889050e-01, ...,\n",
       "          5.73489135e-01,  7.14139060e-01,  9.80986483e-01],\n",
       "        ...,\n",
       "        [-9.83956044e-01,  2.29355609e+00, -1.93470217e+00, ...,\n",
       "          9.88138731e-01,  2.00585253e+00, -9.76859993e-01],\n",
       "        [ 2.79624134e+00, -3.83236605e+00,  9.38764084e-01, ...,\n",
       "          7.29741115e-02,  1.15547812e+00,  2.01198005e+00],\n",
       "        [-2.57159608e+00,  1.52176494e+00, -2.24536595e+00, ...,\n",
       "          2.46218687e-01, -6.12928453e-01,  2.65669360e-01]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1807c8df0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0]+x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11385e5e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[28]+x[28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#reshape the data without noise\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.]], dtype=float32),\n",
       " array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 23:43:43.745428: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 23:43:44.386891: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.8596 - accuracy: 0.7322 - val_loss: 0.4329 - val_accuracy: 0.8734\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3720 - accuracy: 0.8886 - val_loss: 0.2905 - val_accuracy: 0.9128\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2813 - accuracy: 0.9156 - val_loss: 0.2257 - val_accuracy: 0.9317\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2236 - accuracy: 0.9326 - val_loss: 0.1901 - val_accuracy: 0.9422\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1831 - accuracy: 0.9440 - val_loss: 0.1587 - val_accuracy: 0.9512\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1563 - accuracy: 0.9529 - val_loss: 0.1383 - val_accuracy: 0.9574\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1361 - accuracy: 0.9593 - val_loss: 0.1192 - val_accuracy: 0.9638\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1216 - accuracy: 0.9630 - val_loss: 0.1139 - val_accuracy: 0.9656\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.1084 - accuracy: 0.9672 - val_loss: 0.1088 - val_accuracy: 0.9677\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0989 - accuracy: 0.9706 - val_loss: 0.1046 - val_accuracy: 0.9679\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0908 - accuracy: 0.9721 - val_loss: 0.0929 - val_accuracy: 0.9707\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0839 - accuracy: 0.9747 - val_loss: 0.0906 - val_accuracy: 0.9727\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0782 - accuracy: 0.9762 - val_loss: 0.0851 - val_accuracy: 0.9739\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0741 - accuracy: 0.9779 - val_loss: 0.0830 - val_accuracy: 0.9754\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0694 - accuracy: 0.9792 - val_loss: 0.0817 - val_accuracy: 0.9757\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0665 - accuracy: 0.9800 - val_loss: 0.0787 - val_accuracy: 0.9775\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0615 - accuracy: 0.9811 - val_loss: 0.0824 - val_accuracy: 0.9761\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0593 - accuracy: 0.9819 - val_loss: 0.0766 - val_accuracy: 0.9769\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0548 - accuracy: 0.9837 - val_loss: 0.0756 - val_accuracy: 0.9768\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0525 - accuracy: 0.9840 - val_loss: 0.0805 - val_accuracy: 0.9785\n",
      "Test loss: 0.08045564591884613\n",
      "Test accuracy: 0.9785000085830688\n"
     ]
    }
   ],
   "source": [
    "# define the model and evaluate without noise\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.8628 - accuracy: 0.7349 - val_loss: 0.4259 - val_accuracy: 0.8763\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3703 - accuracy: 0.8896 - val_loss: 0.2893 - val_accuracy: 0.9141\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2777 - accuracy: 0.9166 - val_loss: 0.2262 - val_accuracy: 0.9304\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2212 - accuracy: 0.9333 - val_loss: 0.1824 - val_accuracy: 0.9451\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1826 - accuracy: 0.9455 - val_loss: 0.1557 - val_accuracy: 0.9536\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1558 - accuracy: 0.9531 - val_loss: 0.1396 - val_accuracy: 0.9601\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1378 - accuracy: 0.9588 - val_loss: 0.1221 - val_accuracy: 0.9628\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1216 - accuracy: 0.9635 - val_loss: 0.1235 - val_accuracy: 0.9619\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1099 - accuracy: 0.9659 - val_loss: 0.1026 - val_accuracy: 0.9688\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1008 - accuracy: 0.9695 - val_loss: 0.0937 - val_accuracy: 0.9724\n",
      "Test loss: 0.09370874613523483\n",
      "Test accuracy: 0.9724000096321106\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.8593 - accuracy: 0.7382 - val_loss: 0.4032 - val_accuracy: 0.8810\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.3719 - accuracy: 0.8895 - val_loss: 0.2925 - val_accuracy: 0.9121\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.2836 - accuracy: 0.9157 - val_loss: 0.2359 - val_accuracy: 0.9283\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2265 - accuracy: 0.9317 - val_loss: 0.1951 - val_accuracy: 0.9405\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1861 - accuracy: 0.9443 - val_loss: 0.1570 - val_accuracy: 0.9523\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1576 - accuracy: 0.9522 - val_loss: 0.1323 - val_accuracy: 0.9593\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1370 - accuracy: 0.9584 - val_loss: 0.1273 - val_accuracy: 0.9603\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1224 - accuracy: 0.9629 - val_loss: 0.1110 - val_accuracy: 0.9659\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1108 - accuracy: 0.9664 - val_loss: 0.1084 - val_accuracy: 0.9682\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1009 - accuracy: 0.9694 - val_loss: 0.0978 - val_accuracy: 0.9709\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0914 - accuracy: 0.9719 - val_loss: 0.1026 - val_accuracy: 0.9688\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0848 - accuracy: 0.9744 - val_loss: 0.0877 - val_accuracy: 0.9750\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0802 - accuracy: 0.9760 - val_loss: 0.0868 - val_accuracy: 0.9738\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0751 - accuracy: 0.9769 - val_loss: 0.0799 - val_accuracy: 0.9767\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0690 - accuracy: 0.9796 - val_loss: 0.0781 - val_accuracy: 0.9778\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0655 - accuracy: 0.9804 - val_loss: 0.0785 - val_accuracy: 0.9774\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0627 - accuracy: 0.9811 - val_loss: 0.0837 - val_accuracy: 0.9773\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0581 - accuracy: 0.9828 - val_loss: 0.0758 - val_accuracy: 0.9772\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0569 - accuracy: 0.9827 - val_loss: 0.0724 - val_accuracy: 0.9790\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0536 - accuracy: 0.9834 - val_loss: 0.0785 - val_accuracy: 0.9789\n",
      "Test loss: 0.07846753299236298\n",
      "Test accuracy: 0.9789000153541565\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.8671 - accuracy: 0.7293 - val_loss: 0.4166 - val_accuracy: 0.8791\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.3685 - accuracy: 0.8916 - val_loss: 0.3025 - val_accuracy: 0.9100\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.2838 - accuracy: 0.9154 - val_loss: 0.2394 - val_accuracy: 0.9265\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2273 - accuracy: 0.9311 - val_loss: 0.1859 - val_accuracy: 0.9413\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1873 - accuracy: 0.9438 - val_loss: 0.1557 - val_accuracy: 0.9525\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1582 - accuracy: 0.9530 - val_loss: 0.1371 - val_accuracy: 0.9573\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1368 - accuracy: 0.9583 - val_loss: 0.1206 - val_accuracy: 0.9652\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1218 - accuracy: 0.9628 - val_loss: 0.1080 - val_accuracy: 0.9667\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1102 - accuracy: 0.9669 - val_loss: 0.1092 - val_accuracy: 0.9675\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0994 - accuracy: 0.9696 - val_loss: 0.0978 - val_accuracy: 0.9701\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0903 - accuracy: 0.9730 - val_loss: 0.0931 - val_accuracy: 0.9714\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0851 - accuracy: 0.9744 - val_loss: 0.0841 - val_accuracy: 0.9737\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0787 - accuracy: 0.9761 - val_loss: 0.0823 - val_accuracy: 0.9739\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0724 - accuracy: 0.9779 - val_loss: 0.0815 - val_accuracy: 0.9752\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0681 - accuracy: 0.9786 - val_loss: 0.0760 - val_accuracy: 0.9773\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0652 - accuracy: 0.9804 - val_loss: 0.0764 - val_accuracy: 0.9777\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0602 - accuracy: 0.9815 - val_loss: 0.0736 - val_accuracy: 0.9783\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0581 - accuracy: 0.9825 - val_loss: 0.0768 - val_accuracy: 0.9770\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0562 - accuracy: 0.9828 - val_loss: 0.0806 - val_accuracy: 0.9763\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0522 - accuracy: 0.9838 - val_loss: 0.0761 - val_accuracy: 0.9788\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0486 - accuracy: 0.9852 - val_loss: 0.0780 - val_accuracy: 0.9775\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0481 - accuracy: 0.9854 - val_loss: 0.0762 - val_accuracy: 0.9783\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0446 - accuracy: 0.9864 - val_loss: 0.0778 - val_accuracy: 0.9791\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0435 - accuracy: 0.9864 - val_loss: 0.0672 - val_accuracy: 0.9811\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0423 - accuracy: 0.9870 - val_loss: 0.0717 - val_accuracy: 0.9814\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0401 - accuracy: 0.9876 - val_loss: 0.0742 - val_accuracy: 0.9804\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0392 - accuracy: 0.9881 - val_loss: 0.0707 - val_accuracy: 0.9814\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0381 - accuracy: 0.9883 - val_loss: 0.0748 - val_accuracy: 0.9789\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0360 - accuracy: 0.9886 - val_loss: 0.0731 - val_accuracy: 0.9795\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0333 - accuracy: 0.9895 - val_loss: 0.0731 - val_accuracy: 0.9802\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0340 - accuracy: 0.9897 - val_loss: 0.0713 - val_accuracy: 0.9809\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0330 - accuracy: 0.9894 - val_loss: 0.0764 - val_accuracy: 0.9814\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0312 - accuracy: 0.9906 - val_loss: 0.0771 - val_accuracy: 0.9799\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0318 - accuracy: 0.9905 - val_loss: 0.0728 - val_accuracy: 0.9810\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0304 - accuracy: 0.9909 - val_loss: 0.0741 - val_accuracy: 0.9816\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0291 - accuracy: 0.9912 - val_loss: 0.0800 - val_accuracy: 0.9803\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0280 - accuracy: 0.9917 - val_loss: 0.0830 - val_accuracy: 0.9793\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0274 - accuracy: 0.9918 - val_loss: 0.0780 - val_accuracy: 0.9803\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0265 - accuracy: 0.9918 - val_loss: 0.0758 - val_accuracy: 0.9828\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 0.0778 - val_accuracy: 0.9824\n",
      "Test loss: 0.07780631631612778\n",
      "Test accuracy: 0.9824000000953674\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.8449 - accuracy: 0.7383 - val_loss: 0.4014 - val_accuracy: 0.8817\n",
      "Epoch 2/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3653 - accuracy: 0.8907 - val_loss: 0.2856 - val_accuracy: 0.9153\n",
      "Epoch 3/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2785 - accuracy: 0.9169 - val_loss: 0.2283 - val_accuracy: 0.9310\n",
      "Epoch 4/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.2227 - accuracy: 0.9333 - val_loss: 0.1818 - val_accuracy: 0.9443\n",
      "Epoch 5/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.1824 - accuracy: 0.9450 - val_loss: 0.1529 - val_accuracy: 0.9534\n",
      "Epoch 6/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1549 - accuracy: 0.9539 - val_loss: 0.1418 - val_accuracy: 0.9547\n",
      "Epoch 7/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.1343 - accuracy: 0.9590 - val_loss: 0.1276 - val_accuracy: 0.9599\n",
      "Epoch 8/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.1200 - accuracy: 0.9641 - val_loss: 0.1088 - val_accuracy: 0.9661\n",
      "Epoch 9/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1086 - accuracy: 0.9679 - val_loss: 0.1088 - val_accuracy: 0.9649\n",
      "Epoch 10/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0991 - accuracy: 0.9703 - val_loss: 0.0990 - val_accuracy: 0.9689\n",
      "Epoch 11/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0914 - accuracy: 0.9721 - val_loss: 0.0889 - val_accuracy: 0.9730\n",
      "Epoch 12/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0848 - accuracy: 0.9743 - val_loss: 0.0880 - val_accuracy: 0.9736\n",
      "Epoch 13/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0784 - accuracy: 0.9763 - val_loss: 0.0861 - val_accuracy: 0.9746\n",
      "Epoch 14/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0726 - accuracy: 0.9776 - val_loss: 0.0772 - val_accuracy: 0.9773\n",
      "Epoch 15/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0691 - accuracy: 0.9789 - val_loss: 0.0925 - val_accuracy: 0.9735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0646 - accuracy: 0.9809 - val_loss: 0.0792 - val_accuracy: 0.9782\n",
      "Epoch 17/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0609 - accuracy: 0.9811 - val_loss: 0.0752 - val_accuracy: 0.9787\n",
      "Epoch 18/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0578 - accuracy: 0.9815 - val_loss: 0.0770 - val_accuracy: 0.9777\n",
      "Epoch 19/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0548 - accuracy: 0.9834 - val_loss: 0.0754 - val_accuracy: 0.9778\n",
      "Epoch 20/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0526 - accuracy: 0.9839 - val_loss: 0.0723 - val_accuracy: 0.9786\n",
      "Epoch 21/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0499 - accuracy: 0.9848 - val_loss: 0.0743 - val_accuracy: 0.9794\n",
      "Epoch 22/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 0.0771 - val_accuracy: 0.9790\n",
      "Epoch 23/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0453 - accuracy: 0.9860 - val_loss: 0.0706 - val_accuracy: 0.9801\n",
      "Epoch 24/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0441 - accuracy: 0.9864 - val_loss: 0.0721 - val_accuracy: 0.9804\n",
      "Epoch 25/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0412 - accuracy: 0.9873 - val_loss: 0.0737 - val_accuracy: 0.9785\n",
      "Epoch 26/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0399 - accuracy: 0.9877 - val_loss: 0.0751 - val_accuracy: 0.9804\n",
      "Epoch 27/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0389 - accuracy: 0.9882 - val_loss: 0.0775 - val_accuracy: 0.9789\n",
      "Epoch 28/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 0.0741 - val_accuracy: 0.9808\n",
      "Epoch 29/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0348 - accuracy: 0.9894 - val_loss: 0.0731 - val_accuracy: 0.9813\n",
      "Epoch 30/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0331 - accuracy: 0.9896 - val_loss: 0.0788 - val_accuracy: 0.9794\n",
      "Epoch 31/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0344 - accuracy: 0.9891 - val_loss: 0.0770 - val_accuracy: 0.9803\n",
      "Epoch 32/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0326 - accuracy: 0.9902 - val_loss: 0.0715 - val_accuracy: 0.9832\n",
      "Epoch 33/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0307 - accuracy: 0.9906 - val_loss: 0.0736 - val_accuracy: 0.9815\n",
      "Epoch 34/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0313 - accuracy: 0.9906 - val_loss: 0.0773 - val_accuracy: 0.9816\n",
      "Epoch 35/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 0.0707 - val_accuracy: 0.9813\n",
      "Epoch 36/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.0732 - val_accuracy: 0.9821\n",
      "Epoch 37/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0273 - accuracy: 0.9914 - val_loss: 0.0767 - val_accuracy: 0.9818\n",
      "Epoch 38/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0260 - accuracy: 0.9919 - val_loss: 0.0773 - val_accuracy: 0.9818\n",
      "Epoch 39/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.0754 - val_accuracy: 0.9822\n",
      "Epoch 40/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0254 - accuracy: 0.9921 - val_loss: 0.0871 - val_accuracy: 0.9814\n",
      "Epoch 41/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0248 - accuracy: 0.9922 - val_loss: 0.0829 - val_accuracy: 0.9808\n",
      "Epoch 42/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0251 - accuracy: 0.9924 - val_loss: 0.0808 - val_accuracy: 0.9822\n",
      "Epoch 43/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0239 - accuracy: 0.9926 - val_loss: 0.0829 - val_accuracy: 0.9822\n",
      "Epoch 44/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0224 - accuracy: 0.9934 - val_loss: 0.0916 - val_accuracy: 0.9798\n",
      "Epoch 45/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0229 - accuracy: 0.9930 - val_loss: 0.0833 - val_accuracy: 0.9819\n",
      "Epoch 46/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0225 - accuracy: 0.9932 - val_loss: 0.0820 - val_accuracy: 0.9816\n",
      "Epoch 47/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.0856 - val_accuracy: 0.9810\n",
      "Epoch 48/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0211 - accuracy: 0.9935 - val_loss: 0.0973 - val_accuracy: 0.9804\n",
      "Epoch 49/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.0859 - val_accuracy: 0.9817\n",
      "Epoch 50/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.0913 - val_accuracy: 0.9819\n",
      "Epoch 51/80\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.0888 - val_accuracy: 0.9813\n",
      "Epoch 52/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0203 - accuracy: 0.9941 - val_loss: 0.0890 - val_accuracy: 0.9822\n",
      "Epoch 53/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 0.0885 - val_accuracy: 0.9822\n",
      "Epoch 54/80\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0912 - val_accuracy: 0.9815\n",
      "Epoch 55/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.0809 - val_accuracy: 0.9829\n",
      "Epoch 56/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 0.0866 - val_accuracy: 0.9827\n",
      "Epoch 57/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0883 - val_accuracy: 0.9830\n",
      "Epoch 58/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.0998 - val_accuracy: 0.9809\n",
      "Epoch 59/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.0968 - val_accuracy: 0.9818\n",
      "Epoch 60/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.1050 - val_accuracy: 0.9811\n",
      "Epoch 61/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.0867 - val_accuracy: 0.9833\n",
      "Epoch 62/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.1009 - val_accuracy: 0.9825\n",
      "Epoch 63/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.1010 - val_accuracy: 0.9822\n",
      "Epoch 64/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.0970 - val_accuracy: 0.9829\n",
      "Epoch 65/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.0933 - val_accuracy: 0.9827\n",
      "Epoch 66/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.1002 - val_accuracy: 0.9830\n",
      "Epoch 67/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.1020 - val_accuracy: 0.9825\n",
      "Epoch 68/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.1027 - val_accuracy: 0.9828\n",
      "Epoch 69/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.1040 - val_accuracy: 0.9832\n",
      "Epoch 70/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.1017 - val_accuracy: 0.9831\n",
      "Epoch 71/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.0987 - val_accuracy: 0.9828\n",
      "Epoch 72/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0986 - val_accuracy: 0.9829\n",
      "Epoch 73/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.1018 - val_accuracy: 0.9837\n",
      "Epoch 74/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.0995 - val_accuracy: 0.9821\n",
      "Epoch 75/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0995 - val_accuracy: 0.9834\n",
      "Epoch 76/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.1239 - val_accuracy: 0.9806\n",
      "Epoch 77/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0995 - val_accuracy: 0.9833\n",
      "Epoch 78/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.1093 - val_accuracy: 0.9836\n",
      "Epoch 79/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.1012 - val_accuracy: 0.9827\n",
      "Epoch 80/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.1105 - val_accuracy: 0.9836\n",
      "Test loss: 0.11048133671283722\n",
      "Test accuracy: 0.9836000204086304\n"
     ]
    }
   ],
   "source": [
    "# define the model and evaluate without noise and different epochs\n",
    "epochs = [10, 20, 40, 80]\n",
    "\n",
    "for epoch in epochs:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epoch,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.09370874613523483, 0.9724000096321106],\n",
       " [0.07846753299236298, 0.9789000153541565],\n",
       " [0.07780631631612778, 0.9824000000953674],\n",
       " [0.11048133671283722, 0.9836000204086304]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10\n",
      "0.1\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3294 - accuracy: 0.1108 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3016 - accuracy: 0.1123 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3017 - accuracy: 0.1123 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3014 - accuracy: 0.1123 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Test loss: 2.3010480403900146\n",
      "Test accuracy: 0.11349999904632568\n",
      "10\n",
      "0.5\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3201 - accuracy: 0.1098 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3019 - accuracy: 0.1123 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3014 - accuracy: 0.1123 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3016 - accuracy: 0.1121 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3014 - accuracy: 0.1123 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Test loss: 2.301054000854492\n",
      "Test accuracy: 0.11349999904632568\n",
      "10\n",
      "1.0\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3065 - accuracy: 0.1115 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3023 - accuracy: 0.1118 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3017 - accuracy: 0.1128 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3014 - accuracy: 0.1123 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3017 - accuracy: 0.1122 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3014 - accuracy: 0.1122 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3016 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3016 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Test loss: 2.301016092300415\n",
      "Test accuracy: 0.11349999904632568\n",
      "10\n",
      "2.0\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3080 - accuracy: 0.1108 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3033 - accuracy: 0.1122 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3016 - accuracy: 0.1122 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3018 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3024 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3030 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1136\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Test loss: 2.3010640144348145\n",
      "Test accuracy: 0.11349999904632568\n",
      "10\n",
      "4.0\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3090 - accuracy: 0.1108 - val_loss: 2.3059 - val_accuracy: 0.1134\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3040 - accuracy: 0.1119 - val_loss: 2.3010 - val_accuracy: 0.1134\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3024 - accuracy: 0.1127 - val_loss: 2.3010 - val_accuracy: 0.1134\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3021 - accuracy: 0.1130 - val_loss: 2.3017 - val_accuracy: 0.1132\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3019 - accuracy: 0.1129 - val_loss: 2.3011 - val_accuracy: 0.1134\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1134 - val_loss: 2.3012 - val_accuracy: 0.1134\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3006 - accuracy: 0.1135 - val_loss: 2.3016 - val_accuracy: 0.1132\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.2999 - accuracy: 0.1142 - val_loss: 2.3013 - val_accuracy: 0.1136\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2991 - accuracy: 0.1143 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Test loss: 2.301105499267578\n",
      "Test accuracy: 0.11349999904632568\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "20\n",
      "0.1\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.7022 - accuracy: 0.1081 - val_loss: 2.3038 - val_accuracy: 0.1105\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3065 - accuracy: 0.1113 - val_loss: 2.3012 - val_accuracy: 0.1137\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3048 - accuracy: 0.1119 - val_loss: 2.3029 - val_accuracy: 0.1105\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3024 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1134\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3029 - accuracy: 0.1126 - val_loss: 2.3012 - val_accuracy: 0.1136\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3018 - accuracy: 0.1125 - val_loss: 2.3012 - val_accuracy: 0.1136\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3013 - accuracy: 0.1126 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3019 - accuracy: 0.1128 - val_loss: 2.3012 - val_accuracy: 0.1134\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3042 - accuracy: 0.1128 - val_loss: 2.3013 - val_accuracy: 0.1131\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3037 - accuracy: 0.1127 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3022 - accuracy: 0.1129 - val_loss: 2.3011 - val_accuracy: 0.1133\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3013 - accuracy: 0.1130 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3014 - accuracy: 0.1130 - val_loss: 2.3016 - val_accuracy: 0.1133\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3024 - accuracy: 0.1131 - val_loss: 2.3011 - val_accuracy: 0.1133\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2999 - accuracy: 0.1131 - val_loss: 2.3011 - val_accuracy: 0.1134\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2999 - accuracy: 0.1131 - val_loss: 2.3010 - val_accuracy: 0.1133\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1133 - val_loss: 2.3013 - val_accuracy: 0.1134\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3003 - accuracy: 0.1131 - val_loss: 2.3014 - val_accuracy: 0.1134\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3009 - accuracy: 0.1133 - val_loss: 2.3011 - val_accuracy: 0.1136\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3004 - accuracy: 0.1135 - val_loss: 2.3017 - val_accuracy: 0.1138\n",
      "Test loss: 2.301701784133911\n",
      "Test accuracy: 0.11379999667406082\n",
      "20\n",
      "0.5\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3005 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1136\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3022 - accuracy: 0.1134 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3064 - accuracy: 0.1134 - val_loss: 2.3010 - val_accuracy: 0.1134\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3013 - accuracy: 0.1135 - val_loss: 2.3010 - val_accuracy: 0.1134\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3004 - accuracy: 0.1134 - val_loss: 2.3016 - val_accuracy: 0.1133\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3004 - accuracy: 0.1134 - val_loss: 2.3013 - val_accuracy: 0.1136\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3005 - accuracy: 0.1135 - val_loss: 2.3010 - val_accuracy: 0.1136\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3013 - accuracy: 0.1135 - val_loss: 2.3011 - val_accuracy: 0.1136\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2997 - accuracy: 0.1135 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3008 - accuracy: 0.1138 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2994 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1136\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3014 - accuracy: 0.1135 - val_loss: 2.3015 - val_accuracy: 0.1134\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2997 - accuracy: 0.1137 - val_loss: 2.3016 - val_accuracy: 0.1136\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3010 - accuracy: 0.1138 - val_loss: 2.3011 - val_accuracy: 0.1136\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2988 - accuracy: 0.1135 - val_loss: 2.3011 - val_accuracy: 0.1136\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3027 - accuracy: 0.1138 - val_loss: 2.3015 - val_accuracy: 0.1134\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3015 - accuracy: 0.1136 - val_loss: 2.3016 - val_accuracy: 0.1135\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3000 - accuracy: 0.1136 - val_loss: 2.3015 - val_accuracy: 0.1136\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2998 - accuracy: 0.1138 - val_loss: 2.3009 - val_accuracy: 0.1135\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2990 - accuracy: 0.1137 - val_loss: 2.3013 - val_accuracy: 0.1134\n",
      "Test loss: 2.301332473754883\n",
      "Test accuracy: 0.11339999735355377\n",
      "20\n",
      "1.0\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.2992 - accuracy: 0.1137 - val_loss: 2.3009 - val_accuracy: 0.1136\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1137 - val_loss: 2.3009 - val_accuracy: 0.1136\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3020 - accuracy: 0.1137 - val_loss: 2.3010 - val_accuracy: 0.1136\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2992 - accuracy: 0.1139 - val_loss: 2.3008 - val_accuracy: 0.1136\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3032 - accuracy: 0.1135 - val_loss: 2.3028 - val_accuracy: 0.1129\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3015 - accuracy: 0.1139 - val_loss: 2.3011 - val_accuracy: 0.1136\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2987 - accuracy: 0.1137 - val_loss: 2.3011 - val_accuracy: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3000 - accuracy: 0.1137 - val_loss: 2.3011 - val_accuracy: 0.1134\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2988 - accuracy: 0.1137 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3010 - accuracy: 0.1140 - val_loss: 2.3012 - val_accuracy: 0.1136\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3020 - accuracy: 0.1138 - val_loss: 2.3010 - val_accuracy: 0.1136\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2990 - accuracy: 0.1139 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3061 - accuracy: 0.1138 - val_loss: 2.3011 - val_accuracy: 0.1136\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3037 - accuracy: 0.1141 - val_loss: 2.4977 - val_accuracy: 0.1132\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2999 - accuracy: 0.1141 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3129 - accuracy: 0.1138 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.2989 - accuracy: 0.1141 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2984 - accuracy: 0.1141 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.2980 - accuracy: 0.1139 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2980 - accuracy: 0.1139 - val_loss: 2.3020 - val_accuracy: 0.1133\n",
      "Test loss: 2.301957130432129\n",
      "Test accuracy: 0.11330000311136246\n",
      "20\n",
      "2.0\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3053 - accuracy: 0.1138 - val_loss: 2.3015 - val_accuracy: 0.1136\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.2983 - accuracy: 0.1138 - val_loss: 2.3011 - val_accuracy: 0.1136\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3037 - accuracy: 0.1137 - val_loss: 2.3036 - val_accuracy: 0.1140\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3142 - accuracy: 0.1138 - val_loss: 2.3012 - val_accuracy: 0.1134\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3017 - accuracy: 0.1142 - val_loss: 2.3021 - val_accuracy: 0.1136\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.2999 - accuracy: 0.1139 - val_loss: 2.3011 - val_accuracy: 0.1136\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3130 - accuracy: 0.1138 - val_loss: 2.3018 - val_accuracy: 0.1140\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3083 - accuracy: 0.1139 - val_loss: 2.3169 - val_accuracy: 0.1126\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2983 - accuracy: 0.1141 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2979 - accuracy: 0.1138 - val_loss: 2.3010 - val_accuracy: 0.1134\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2983 - accuracy: 0.1138 - val_loss: 2.3016 - val_accuracy: 0.1138\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2986 - accuracy: 0.1139 - val_loss: 2.3010 - val_accuracy: 0.1137\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3010 - accuracy: 0.1141 - val_loss: 2.3012 - val_accuracy: 0.1134\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.2999 - accuracy: 0.1140 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3026 - accuracy: 0.1142 - val_loss: 2.3011 - val_accuracy: 0.1134\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3023 - accuracy: 0.1140 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3000 - accuracy: 0.1140 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3018 - accuracy: 0.1138 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2987 - accuracy: 0.1140 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3002 - accuracy: 0.1139 - val_loss: 2.3009 - val_accuracy: 0.1136\n",
      "Test loss: 2.3009259700775146\n",
      "Test accuracy: 0.1136000007390976\n",
      "20\n",
      "4.0\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3103 - accuracy: 0.1134 - val_loss: 2.3008 - val_accuracy: 0.1136\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3038 - accuracy: 0.1137 - val_loss: 2.3012 - val_accuracy: 0.1136\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3102 - accuracy: 0.1136 - val_loss: 2.3033 - val_accuracy: 0.1134\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3053 - accuracy: 0.1138 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3029 - accuracy: 0.1138 - val_loss: 2.3020 - val_accuracy: 0.1132\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3050 - accuracy: 0.1137 - val_loss: 2.3064 - val_accuracy: 0.1135\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2997 - accuracy: 0.1139 - val_loss: 2.3011 - val_accuracy: 0.1134\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3049 - accuracy: 0.1135 - val_loss: 2.3011 - val_accuracy: 0.1136\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3019 - accuracy: 0.1137 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2994 - accuracy: 0.1137 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3027 - accuracy: 0.1140 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3009 - accuracy: 0.1138 - val_loss: 2.3012 - val_accuracy: 0.1137\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2991 - accuracy: 0.1139 - val_loss: 2.3011 - val_accuracy: 0.1134\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3028 - accuracy: 0.1138 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3001 - accuracy: 0.1138 - val_loss: 2.3011 - val_accuracy: 0.1134\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3010 - accuracy: 0.1138 - val_loss: 2.3011 - val_accuracy: 0.1136\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2995 - accuracy: 0.1138 - val_loss: 2.3010 - val_accuracy: 0.1134\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1138 - val_loss: 2.3011 - val_accuracy: 0.1134\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2977 - accuracy: 0.1139 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2997 - accuracy: 0.1138 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Test loss: 2.3010573387145996\n",
      "Test accuracy: 0.11349999904632568\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 3.1193 - accuracy: 0.1082 - val_loss: 2.3012 - val_accuracy: 0.1136\n",
      "Epoch 2/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3063 - accuracy: 0.1119 - val_loss: 2.3012 - val_accuracy: 0.1138\n",
      "Epoch 3/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3138 - accuracy: 0.1121 - val_loss: 2.3013 - val_accuracy: 0.1136\n",
      "Epoch 4/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3038 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 5/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3077 - accuracy: 0.1123 - val_loss: 2.3012 - val_accuracy: 0.1134\n",
      "Epoch 6/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3030 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1136\n",
      "Epoch 7/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3024 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 8/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3014 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1136\n",
      "Epoch 9/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3017 - accuracy: 0.1123 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 10/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3013 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 11/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 12/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 13/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 14/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3017 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 15/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 16/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 17/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3036 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 18/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 19/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 20/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 21/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 22/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 23/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 24/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 25/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 26/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 27/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 28/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 29/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 30/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 31/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 32/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 33/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 34/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 35/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 36/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 37/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 38/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 39/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 40/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 41/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 42/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 43/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 44/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 45/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 46/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 47/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 48/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 49/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 50/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 51/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 52/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 53/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 54/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 55/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 56/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 57/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 58/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 59/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 60/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 61/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 62/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 63/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 64/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 65/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 66/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 67/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 68/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 69/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 70/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 71/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 72/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 73/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 74/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 75/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 76/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 77/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 78/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 79/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 80/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Test loss: 2.301002264022827\n",
      "Test accuracy: 0.11349999904632568\n",
      "80\n",
      "0.5\n",
      "Epoch 1/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 2/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3071 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 3/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 4/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 5/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 6/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 7/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 8/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 9/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 10/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 11/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 12/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 13/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 14/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 15/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 16/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 17/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 18/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 19/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 20/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 21/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 22/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 23/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 24/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 25/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 26/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 27/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 28/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 29/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 30/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 31/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 32/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 33/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 34/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 36/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 37/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 38/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 39/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 40/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 41/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 42/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 43/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 44/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 45/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 46/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 47/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 48/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 49/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 50/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 51/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 52/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 53/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 54/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 55/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 56/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 57/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 58/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 59/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 60/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 61/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 62/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 63/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 64/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 65/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 66/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 67/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 68/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 69/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 70/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 71/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 72/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 73/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 74/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 75/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 76/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 77/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 78/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 79/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 80/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Test loss: 2.3010101318359375\n",
      "Test accuracy: 0.11349999904632568\n",
      "80\n",
      "1.0\n",
      "Epoch 1/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 2/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 3/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 4/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 5/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 6/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 7/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 8/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 9/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 10/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 11/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 13/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 14/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 15/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 16/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 17/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 18/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 19/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 20/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 21/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 22/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 23/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 24/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 25/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 26/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 27/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 28/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 29/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 30/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 31/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 32/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 33/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 34/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 35/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 36/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 37/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 38/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 39/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 40/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 41/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 42/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 43/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 44/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 45/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 46/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 47/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 48/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 49/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 50/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 51/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 52/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 53/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 54/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 55/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 56/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 57/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 58/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 59/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 60/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 61/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 62/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 63/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 64/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 65/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 66/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 67/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 68/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 69/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 70/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 71/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 72/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 73/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 74/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 75/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 76/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 77/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 78/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 79/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 80/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Test loss: 2.301025867462158\n",
      "Test accuracy: 0.11349999904632568\n",
      "80\n",
      "2.0\n",
      "Epoch 1/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 2/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 3/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 4/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 5/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 6/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 7/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 8/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 9/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 10/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 11/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 12/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 13/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 14/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 15/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 16/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 17/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 18/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 19/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 20/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 21/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 22/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 23/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 24/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 25/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 26/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 27/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 28/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 29/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 30/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 31/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 32/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 33/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 34/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 35/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 36/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 37/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 38/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 39/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 40/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 41/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 42/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 43/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 44/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 45/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 47/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 48/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 49/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 50/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 51/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 52/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 53/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 54/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 55/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 56/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 57/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 58/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 59/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 60/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 61/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 62/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 63/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 64/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 65/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 66/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 67/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 68/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 69/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 70/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 71/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 72/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 73/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 74/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 75/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 76/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 77/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 78/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 79/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 80/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Test loss: 2.3010172843933105\n",
      "Test accuracy: 0.11349999904632568\n",
      "80\n",
      "4.0\n",
      "Epoch 1/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3016 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 2/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3013 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 3/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 4/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3040 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 5/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3032 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 6/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 7/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 8/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3162 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 9/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 10/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 11/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3018 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 12/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3033 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 13/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 14/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1136\n",
      "Epoch 15/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 16/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 17/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3014 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 18/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 19/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 20/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3012 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 21/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 22/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3010 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 24/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3010 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 25/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 26/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 27/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3010 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 28/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3010 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 29/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 30/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 31/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 32/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 33/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 34/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 35/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 36/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3010 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 37/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 38/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 39/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 40/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 41/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3010 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 42/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 43/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 44/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3010 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 45/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 46/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3010 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 47/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 48/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 49/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 50/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 51/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 52/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 53/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 54/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 55/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 56/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 57/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 58/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 59/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 60/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 61/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3010 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 62/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 63/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 64/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 65/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 66/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3010 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 67/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 68/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 69/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 70/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3121 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 71/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3011 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 72/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3010 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 73/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3025 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 74/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3010 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 75/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3013 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 76/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3012 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 77/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3012 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 78/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3030 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 79/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 80/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3013 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Test loss: 2.3010172843933105\n",
      "Test accuracy: 0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "# add different noise scales\n",
    "scales = [.1, .5, 1.0, 2.0, 4.0]\n",
    "epochs = [10, 20, 80]\n",
    "scores_n = []\n",
    "for epoch in epochs:\n",
    "    \n",
    "    # build model and evaluate\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "\n",
    "    for scale in scales:\n",
    "        print(epoch)\n",
    "        print(scale)\n",
    "        \n",
    "        x = random.normal(loc=1, scale=scale, size=x_train.shape)\n",
    "        x_train = x_train + x\n",
    "        \n",
    "        x = random.normal(loc=1, scale=scale, size=x_test.shape)\n",
    "        x_test = x_test + x\n",
    "        \n",
    "        history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "        \n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        \n",
    "        scores_n.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0.09370874613523483, 0.9724000096321106],\n",
       "  [0.07846753299236298, 0.9789000153541565],\n",
       "  [0.07780631631612778, 0.9824000000953674],\n",
       "  [0.11048133671283722, 0.9836000204086304]],\n",
       " [[2.3010480403900146, 0.11349999904632568],\n",
       "  [2.301054000854492, 0.11349999904632568],\n",
       "  [2.301016092300415, 0.11349999904632568],\n",
       "  [2.3010640144348145, 0.11349999904632568],\n",
       "  [2.301105499267578, 0.11349999904632568],\n",
       "  [2.301701784133911, 0.11379999667406082],\n",
       "  [2.301332473754883, 0.11339999735355377],\n",
       "  [2.301957130432129, 0.11330000311136246],\n",
       "  [2.3009259700775146, 0.1136000007390976],\n",
       "  [2.3010573387145996, 0.11349999904632568],\n",
       "  [2.301002264022827, 0.11349999904632568],\n",
       "  [2.3010101318359375, 0.11349999904632568],\n",
       "  [2.301025867462158, 0.11349999904632568],\n",
       "  [2.3010172843933105, 0.11349999904632568],\n",
       "  [2.3010172843933105, 0.11349999904632568]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, scores_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       loss  accuracy\n",
       " 0  0.093709    0.9724\n",
       " 1  0.078468    0.9789\n",
       " 2  0.077806    0.9824\n",
       " 3  0.110481    0.9836,\n",
       "         loss  accuracy\n",
       " 0   2.301048    0.1135\n",
       " 1   2.301054    0.1135\n",
       " 2   2.301016    0.1135\n",
       " 3   2.301064    0.1135\n",
       " 4   2.301105    0.1135\n",
       " 5   2.301702    0.1138\n",
       " 6   2.301332    0.1134\n",
       " 7   2.301957    0.1133\n",
       " 8   2.300926    0.1136\n",
       " 9   2.301057    0.1135\n",
       " 10  2.301002    0.1135\n",
       " 11  2.301010    0.1135\n",
       " 12  2.301026    0.1135\n",
       " 13  2.301017    0.1135\n",
       " 14  2.301017    0.1135)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "scoresdf = pd.DataFrame(scores, columns=['loss','accuracy'])\n",
    "scoresndf = pd.DataFrame(scores_n, columns=['loss','accuracy'])\n",
    "\n",
    "scoresdf, scoresndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy Scores')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(scoresdf.index, scoresdf['accuracy'])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Accuracy Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy Scores')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(scoresndf.index, scoresndf['accuracy'])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Accuracy Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

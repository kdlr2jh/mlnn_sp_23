{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks image recognition - MultiLayer Perceptron\n",
    "Use both MLNN for the following problem.\n",
    "\n",
    "1. Add random noise (see below on `size parameter` on [`np.random.normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html)) to the images in training and testing. **Make sure each image gets a different noise feature added to it. Inspect by printing out several images. Note - the `size` parameter should match the data. **\n",
    "2. Compare the `accuracy` of train and val after N epochs for MLNN with and without noise. \n",
    "3. Vary the amount of noise by changing the `scale` parameter in `np.random.normal` by a factor. Use `.1, .5, 1.0, 2.0, 4.0` for the `scale` and keep track of the `accuracy` for training and validation and plot these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `np.random.normal`\n",
    "\n",
    "## Parameters\n",
    "\n",
    "### loc\n",
    "\n",
    "Mean (“centre”) of the distribution.\n",
    "\n",
    "### scale\n",
    "\n",
    "Standard deviation (spread or “width”) of the distribution. Must be non-negative.\n",
    "\n",
    "### size\n",
    "\n",
    "Output shape. If the given shape is, e.g., (m, n, k), then m * n * k samples are drawn. If size is None (default), a single value is returned if loc and scale are both scalars. Otherwise, np.broadcast(loc, scale).size samples are drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Image Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as  plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Neural Network\n",
    "Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x165229ac0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-2.70972124e-01,  5.13941261e+00,  3.30137384e-01, ...,\n",
       "          2.47816735e+00,  1.87176698e+00, -4.68066066e-01],\n",
       "        [ 2.40034368e+00,  3.66772158e+00, -2.40991144e+00, ...,\n",
       "          4.69781568e+00,  1.74609606e+00, -1.76416211e+00],\n",
       "        [ 1.84793024e+00,  6.86165833e-01,  1.52192628e+00, ...,\n",
       "          1.85583931e+00, -1.02518963e+00,  2.75924489e+00],\n",
       "        ...,\n",
       "        [ 3.40829458e+00,  1.99450168e+00,  3.73585389e+00, ...,\n",
       "          3.40912804e+00, -1.04026790e+00, -1.41305639e+00],\n",
       "        [-2.34194905e+00,  1.66938398e+00, -8.47634547e-01, ...,\n",
       "          2.83815127e+00, -6.22977900e+00, -1.95284282e+00],\n",
       "        [ 4.84803649e+00, -1.31814245e+00, -3.45057852e-01, ...,\n",
       "         -6.85164028e-01,  2.24158974e+00,  2.23348333e+00]],\n",
       "\n",
       "       [[ 2.57807834e+00,  2.29527438e+00,  2.87235212e-01, ...,\n",
       "          1.09336769e+00,  2.93519540e+00,  2.01274333e+00],\n",
       "        [ 5.35716096e+00,  4.49205302e+00,  5.44040271e-01, ...,\n",
       "         -7.47648394e-01,  1.22725143e+00,  1.79301525e+00],\n",
       "        [-1.77621345e+00, -1.77123843e+00,  3.19226890e+00, ...,\n",
       "          2.89288854e+00,  3.23279361e+00, -1.81203139e+00],\n",
       "        ...,\n",
       "        [ 3.07171010e+00,  4.07200480e+00,  7.51251441e-01, ...,\n",
       "          2.94729053e+00,  2.95071186e+00, -3.49067402e-01],\n",
       "        [ 1.03692689e+00,  8.36626077e-02,  2.44711462e+00, ...,\n",
       "          7.12608828e-01,  3.70026904e+00, -1.07917735e+00],\n",
       "        [ 1.11778681e+00,  4.19219944e-01, -1.61990270e+00, ...,\n",
       "          5.56663469e-01,  2.36195868e+00,  2.71038984e-01]],\n",
       "\n",
       "       [[ 8.46368090e-01,  2.03041437e+00,  4.84056410e+00, ...,\n",
       "         -2.92570440e+00, -8.08174090e-01,  1.13396408e+00],\n",
       "        [ 2.40863346e+00,  7.75735507e-01,  2.47099422e-01, ...,\n",
       "          1.41940672e+00,  9.65173854e-01,  2.54392945e+00],\n",
       "        [ 2.92046552e+00,  1.15278064e-01,  4.34317566e-01, ...,\n",
       "          8.27918130e-01,  4.55352123e+00, -2.17860200e+00],\n",
       "        ...,\n",
       "        [-2.52048634e+00, -8.89644663e-01,  9.66236574e-01, ...,\n",
       "         -1.83865529e+00, -1.75368916e+00, -1.08839341e+00],\n",
       "        [ 1.81718700e+00,  1.67554840e+00,  1.86914722e+00, ...,\n",
       "         -2.24690542e+00,  2.58317858e+00,  7.39447667e-01],\n",
       "        [ 1.05494946e+00,  4.56925556e+00,  1.03327017e+00, ...,\n",
       "         -4.79292452e-03, -1.08444784e+00,  6.45844787e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-7.64220225e-01,  4.30692751e+00,  2.14741248e+00, ...,\n",
       "         -1.24566171e+00,  8.66228221e-01,  6.68561481e-01],\n",
       "        [ 1.26273873e+00,  1.00056916e+00,  1.11344837e+00, ...,\n",
       "          2.94605226e+00,  1.41425660e+00,  1.62896731e+00],\n",
       "        [ 2.98555712e+00,  3.69172720e+00, -9.20861983e-01, ...,\n",
       "          3.15567785e+00,  4.40690742e+00, -8.97334504e-01],\n",
       "        ...,\n",
       "        [ 2.39848550e+00,  3.11141746e+00, -6.43949262e-01, ...,\n",
       "         -7.17997321e-01,  3.23452684e-01,  8.73804823e-01],\n",
       "        [-7.96017343e-01,  2.42190529e+00, -1.01941678e+00, ...,\n",
       "          3.58141684e+00,  2.44465774e+00,  7.73956414e-01],\n",
       "        [ 5.75566743e-01,  2.39306639e+00,  3.22979665e-01, ...,\n",
       "         -5.93059202e-01,  2.99087336e+00,  2.40975770e+00]],\n",
       "\n",
       "       [[ 4.57593892e+00, -2.65628826e+00,  3.43485663e+00, ...,\n",
       "          1.36848014e+00,  2.36269279e-01,  4.13248210e+00],\n",
       "        [ 3.94742093e+00,  1.57068105e-01, -1.75753441e+00, ...,\n",
       "          1.64005336e-01,  6.30873307e-01, -1.71158369e+00],\n",
       "        [ 2.37009676e+00, -7.85591534e-01,  2.95136322e+00, ...,\n",
       "          4.96851867e-01,  2.37855223e+00,  8.19207935e-01],\n",
       "        ...,\n",
       "        [-4.88178143e-01,  9.73403521e-01,  2.26164305e+00, ...,\n",
       "         -8.52955060e-03,  6.13267539e-01,  1.30761101e+00],\n",
       "        [ 3.54580952e-01, -2.30120789e+00,  1.91993430e+00, ...,\n",
       "          9.64159869e-01, -6.20813193e-01, -1.11512610e+00],\n",
       "        [ 1.96089697e+00,  1.36068970e+00,  7.71857909e-01, ...,\n",
       "          3.81618560e-01, -8.70511149e-01, -1.96331498e+00]],\n",
       "\n",
       "       [[-1.02447785e+00,  4.84606542e-01,  3.50444516e+00, ...,\n",
       "          8.54860703e-01,  1.13310179e+00, -1.14644658e+00],\n",
       "        [ 1.60237966e+00, -1.08899107e+00,  2.94012576e+00, ...,\n",
       "          1.34092081e+00,  2.67728770e+00,  2.29729638e+00],\n",
       "        [-8.47018015e-01,  2.91652429e+00,  5.89372484e-01, ...,\n",
       "          1.54834142e+00,  2.28152375e+00, -1.52280794e+00],\n",
       "        ...,\n",
       "        [-1.88833914e+00,  3.16330711e+00,  1.52309203e+00, ...,\n",
       "         -7.05351389e-01, -2.93084074e+00, -5.68496961e-01],\n",
       "        [ 2.00793809e+00,  1.62179423e+00,  1.66298232e+00, ...,\n",
       "         -7.95083221e-01,  6.13500821e-01, -3.50503005e+00],\n",
       "        [ 1.58224661e-01,  4.28293948e+00, -2.25299118e-01, ...,\n",
       "         -5.64449510e-01,  4.24919984e-01,  6.14049902e-01]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import random\n",
    "\n",
    "x = random.normal(loc=1, scale=2, size=x_train.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-2.70972124e-01,  5.13941261e+00,  3.30137384e-01, ...,\n",
       "          2.47816735e+00,  1.87176698e+00, -4.68066066e-01],\n",
       "        [ 2.40034368e+00,  3.66772158e+00, -2.40991144e+00, ...,\n",
       "          4.69781568e+00,  1.74609606e+00, -1.76416211e+00],\n",
       "        [ 1.84793024e+00,  6.86165833e-01,  1.52192628e+00, ...,\n",
       "          1.85583931e+00, -1.02518963e+00,  2.75924489e+00],\n",
       "        ...,\n",
       "        [ 3.40829458e+00,  1.99450168e+00,  3.73585389e+00, ...,\n",
       "          3.40912804e+00, -1.04026790e+00, -1.41305639e+00],\n",
       "        [-2.34194905e+00,  1.66938398e+00, -8.47634547e-01, ...,\n",
       "          2.83815127e+00, -6.22977900e+00, -1.95284282e+00],\n",
       "        [ 4.84803649e+00, -1.31814245e+00, -3.45057852e-01, ...,\n",
       "         -6.85164028e-01,  2.24158974e+00,  2.23348333e+00]],\n",
       "\n",
       "       [[ 2.57807834e+00,  2.29527438e+00,  2.87235212e-01, ...,\n",
       "          1.09336769e+00,  2.93519540e+00,  2.01274333e+00],\n",
       "        [ 5.35716096e+00,  4.49205302e+00,  5.44040271e-01, ...,\n",
       "         -7.47648394e-01,  1.22725143e+00,  1.79301525e+00],\n",
       "        [-1.77621345e+00, -1.77123843e+00,  3.19226890e+00, ...,\n",
       "          2.89288854e+00,  3.23279361e+00, -1.81203139e+00],\n",
       "        ...,\n",
       "        [ 3.07171010e+00,  4.07200480e+00,  7.51251441e-01, ...,\n",
       "          2.94729053e+00,  2.95071186e+00, -3.49067402e-01],\n",
       "        [ 1.03692689e+00,  8.36626077e-02,  2.44711462e+00, ...,\n",
       "          7.12608828e-01,  3.70026904e+00, -1.07917735e+00],\n",
       "        [ 1.11778681e+00,  4.19219944e-01, -1.61990270e+00, ...,\n",
       "          5.56663469e-01,  2.36195868e+00,  2.71038984e-01]],\n",
       "\n",
       "       [[ 8.46368090e-01,  2.03041437e+00,  4.84056410e+00, ...,\n",
       "         -2.92570440e+00, -8.08174090e-01,  1.13396408e+00],\n",
       "        [ 2.40863346e+00,  7.75735507e-01,  2.47099422e-01, ...,\n",
       "          1.41940672e+00,  9.65173854e-01,  2.54392945e+00],\n",
       "        [ 2.92046552e+00,  1.15278064e-01,  4.34317566e-01, ...,\n",
       "          8.27918130e-01,  4.55352123e+00, -2.17860200e+00],\n",
       "        ...,\n",
       "        [-2.52048634e+00, -8.89644663e-01,  9.66236574e-01, ...,\n",
       "         -1.83865529e+00, -1.75368916e+00, -1.08839341e+00],\n",
       "        [ 1.81718700e+00,  1.67554840e+00,  1.86914722e+00, ...,\n",
       "         -2.24690542e+00,  2.58317858e+00,  7.39447667e-01],\n",
       "        [ 1.05494946e+00,  4.56925556e+00,  1.03327017e+00, ...,\n",
       "         -4.79292452e-03, -1.08444784e+00,  6.45844787e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-7.64220225e-01,  4.30692751e+00,  2.14741248e+00, ...,\n",
       "         -1.24566171e+00,  8.66228221e-01,  6.68561481e-01],\n",
       "        [ 1.26273873e+00,  1.00056916e+00,  1.11344837e+00, ...,\n",
       "          2.94605226e+00,  1.41425660e+00,  1.62896731e+00],\n",
       "        [ 2.98555712e+00,  3.69172720e+00, -9.20861983e-01, ...,\n",
       "          3.15567785e+00,  4.40690742e+00, -8.97334504e-01],\n",
       "        ...,\n",
       "        [ 2.39848550e+00,  3.11141746e+00, -6.43949262e-01, ...,\n",
       "         -7.17997321e-01,  3.23452684e-01,  8.73804823e-01],\n",
       "        [-7.96017343e-01,  2.42190529e+00, -1.01941678e+00, ...,\n",
       "          3.58141684e+00,  2.44465774e+00,  7.73956414e-01],\n",
       "        [ 5.75566743e-01,  2.39306639e+00,  3.22979665e-01, ...,\n",
       "         -5.93059202e-01,  2.99087336e+00,  2.40975770e+00]],\n",
       "\n",
       "       [[ 4.57593892e+00, -2.65628826e+00,  3.43485663e+00, ...,\n",
       "          1.36848014e+00,  2.36269279e-01,  4.13248210e+00],\n",
       "        [ 3.94742093e+00,  1.57068105e-01, -1.75753441e+00, ...,\n",
       "          1.64005336e-01,  6.30873307e-01, -1.71158369e+00],\n",
       "        [ 2.37009676e+00, -7.85591534e-01,  2.95136322e+00, ...,\n",
       "          4.96851867e-01,  2.37855223e+00,  8.19207935e-01],\n",
       "        ...,\n",
       "        [-4.88178143e-01,  9.73403521e-01,  2.26164305e+00, ...,\n",
       "         -8.52955060e-03,  6.13267539e-01,  1.30761101e+00],\n",
       "        [ 3.54580952e-01, -2.30120789e+00,  1.91993430e+00, ...,\n",
       "          9.64159869e-01, -6.20813193e-01, -1.11512610e+00],\n",
       "        [ 1.96089697e+00,  1.36068970e+00,  7.71857909e-01, ...,\n",
       "          3.81618560e-01, -8.70511149e-01, -1.96331498e+00]],\n",
       "\n",
       "       [[-1.02447785e+00,  4.84606542e-01,  3.50444516e+00, ...,\n",
       "          8.54860703e-01,  1.13310179e+00, -1.14644658e+00],\n",
       "        [ 1.60237966e+00, -1.08899107e+00,  2.94012576e+00, ...,\n",
       "          1.34092081e+00,  2.67728770e+00,  2.29729638e+00],\n",
       "        [-8.47018015e-01,  2.91652429e+00,  5.89372484e-01, ...,\n",
       "          1.54834142e+00,  2.28152375e+00, -1.52280794e+00],\n",
       "        ...,\n",
       "        [-1.88833914e+00,  3.16330711e+00,  1.52309203e+00, ...,\n",
       "         -7.05351389e-01, -2.93084074e+00, -5.68496961e-01],\n",
       "        [ 2.00793809e+00,  1.62179423e+00,  1.66298232e+00, ...,\n",
       "         -7.95083221e-01,  6.13500821e-01, -3.50503005e+00],\n",
       "        [ 1.58224661e-01,  4.28293948e+00, -2.25299118e-01, ...,\n",
       "         -5.64449510e-01,  4.24919984e-01,  6.14049902e-01]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17c5f6e80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0]+x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12b4947f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[28]+x[28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#reshape the data without noise\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.]], dtype=float32),\n",
       " array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 00:36:49.067569: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 00:36:49.719696: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.2447 - accuracy: 0.9238 - val_loss: 0.1206 - val_accuracy: 0.9639\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1039 - accuracy: 0.9685 - val_loss: 0.1000 - val_accuracy: 0.9696\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0731 - accuracy: 0.9774 - val_loss: 0.0712 - val_accuracy: 0.9775\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0598 - accuracy: 0.9814 - val_loss: 0.0707 - val_accuracy: 0.9816\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0508 - accuracy: 0.9847 - val_loss: 0.0687 - val_accuracy: 0.9811\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0444 - accuracy: 0.9872 - val_loss: 0.0850 - val_accuracy: 0.9787\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0390 - accuracy: 0.9886 - val_loss: 0.0771 - val_accuracy: 0.9838\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0360 - accuracy: 0.9894 - val_loss: 0.0788 - val_accuracy: 0.9814\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0310 - accuracy: 0.9912 - val_loss: 0.0843 - val_accuracy: 0.9823\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0272 - accuracy: 0.9920 - val_loss: 0.0846 - val_accuracy: 0.9824\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0261 - accuracy: 0.9925 - val_loss: 0.0979 - val_accuracy: 0.9818\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0254 - accuracy: 0.9925 - val_loss: 0.0953 - val_accuracy: 0.9827\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0226 - accuracy: 0.9934 - val_loss: 0.1126 - val_accuracy: 0.9824\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0224 - accuracy: 0.9938 - val_loss: 0.1096 - val_accuracy: 0.9814\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.1146 - val_accuracy: 0.9828\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0209 - accuracy: 0.9946 - val_loss: 0.1059 - val_accuracy: 0.9822\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0211 - accuracy: 0.9941 - val_loss: 0.1114 - val_accuracy: 0.9832\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 0.1157 - val_accuracy: 0.9837\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.1155 - val_accuracy: 0.9835\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0179 - accuracy: 0.9954 - val_loss: 0.1236 - val_accuracy: 0.9831\n",
      "Test loss: 0.12355146557092667\n",
      "Test accuracy: 0.9830999970436096\n"
     ]
    }
   ],
   "source": [
    "# define the model and evaluate without noise\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.2477 - accuracy: 0.9233 - val_loss: 0.1011 - val_accuracy: 0.9690\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1026 - accuracy: 0.9687 - val_loss: 0.1007 - val_accuracy: 0.9711\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0752 - accuracy: 0.9774 - val_loss: 0.0806 - val_accuracy: 0.9771\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0603 - accuracy: 0.9819 - val_loss: 0.0686 - val_accuracy: 0.9809\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0497 - accuracy: 0.9852 - val_loss: 0.0768 - val_accuracy: 0.9805\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0438 - accuracy: 0.9868 - val_loss: 0.0775 - val_accuracy: 0.9807\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0399 - accuracy: 0.9882 - val_loss: 0.0781 - val_accuracy: 0.9816\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0336 - accuracy: 0.9899 - val_loss: 0.0691 - val_accuracy: 0.9827\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0301 - accuracy: 0.9908 - val_loss: 0.0868 - val_accuracy: 0.9812\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0291 - accuracy: 0.9916 - val_loss: 0.0793 - val_accuracy: 0.9825\n",
      "Test loss: 0.07930032908916473\n",
      "Test accuracy: 0.9825000166893005\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2478 - accuracy: 0.9241 - val_loss: 0.1009 - val_accuracy: 0.9681\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1037 - accuracy: 0.9683 - val_loss: 0.0810 - val_accuracy: 0.9747\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0738 - accuracy: 0.9774 - val_loss: 0.0701 - val_accuracy: 0.9785\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0599 - accuracy: 0.9824 - val_loss: 0.0728 - val_accuracy: 0.9787\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0507 - accuracy: 0.9845 - val_loss: 0.0744 - val_accuracy: 0.9803\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0431 - accuracy: 0.9871 - val_loss: 0.0786 - val_accuracy: 0.9808\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0384 - accuracy: 0.9886 - val_loss: 0.0854 - val_accuracy: 0.9796\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 0.0871 - val_accuracy: 0.9825\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0310 - accuracy: 0.9911 - val_loss: 0.0893 - val_accuracy: 0.9811\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0293 - accuracy: 0.9917 - val_loss: 0.1035 - val_accuracy: 0.9814\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.0922 - val_accuracy: 0.9832\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0257 - accuracy: 0.9924 - val_loss: 0.1002 - val_accuracy: 0.9812\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.1052 - val_accuracy: 0.9821\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.1139 - val_accuracy: 0.9817\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.1208 - val_accuracy: 0.9824\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 0.1363 - val_accuracy: 0.9802\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0191 - accuracy: 0.9948 - val_loss: 0.1014 - val_accuracy: 0.9849\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0165 - accuracy: 0.9959 - val_loss: 0.1283 - val_accuracy: 0.9834\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0180 - accuracy: 0.9952 - val_loss: 0.1330 - val_accuracy: 0.9835\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0170 - accuracy: 0.9955 - val_loss: 0.1487 - val_accuracy: 0.9826\n",
      "Test loss: 0.148671954870224\n",
      "Test accuracy: 0.9825999736785889\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2453 - accuracy: 0.9247 - val_loss: 0.1067 - val_accuracy: 0.9657\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1024 - accuracy: 0.9690 - val_loss: 0.0818 - val_accuracy: 0.9765\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0747 - accuracy: 0.9780 - val_loss: 0.0757 - val_accuracy: 0.9773\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0605 - accuracy: 0.9814 - val_loss: 0.0724 - val_accuracy: 0.9800\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0507 - accuracy: 0.9850 - val_loss: 0.0677 - val_accuracy: 0.9827\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0450 - accuracy: 0.9862 - val_loss: 0.0723 - val_accuracy: 0.9808\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0377 - accuracy: 0.9886 - val_loss: 0.0809 - val_accuracy: 0.9814\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0345 - accuracy: 0.9894 - val_loss: 0.0805 - val_accuracy: 0.9837\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 0.0764 - val_accuracy: 0.9843\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0284 - accuracy: 0.9910 - val_loss: 0.1047 - val_accuracy: 0.9803\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 0.1035 - val_accuracy: 0.9832\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0261 - accuracy: 0.9926 - val_loss: 0.1131 - val_accuracy: 0.9820\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0242 - accuracy: 0.9930 - val_loss: 0.0948 - val_accuracy: 0.9839\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0217 - accuracy: 0.9934 - val_loss: 0.1000 - val_accuracy: 0.9828\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0216 - accuracy: 0.9940 - val_loss: 0.0978 - val_accuracy: 0.9832\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.1174 - val_accuracy: 0.9820\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0212 - accuracy: 0.9941 - val_loss: 0.1147 - val_accuracy: 0.9820\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.1102 - val_accuracy: 0.9846\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 0.1243 - val_accuracy: 0.9839\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0188 - accuracy: 0.9952 - val_loss: 0.1296 - val_accuracy: 0.9848\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0163 - accuracy: 0.9958 - val_loss: 0.1233 - val_accuracy: 0.9825\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0171 - accuracy: 0.9958 - val_loss: 0.1358 - val_accuracy: 0.9837\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.1462 - val_accuracy: 0.9836\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.1361 - val_accuracy: 0.9822\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0160 - accuracy: 0.9961 - val_loss: 0.1518 - val_accuracy: 0.9841\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.1481 - val_accuracy: 0.9837\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0148 - accuracy: 0.9966 - val_loss: 0.1538 - val_accuracy: 0.9848\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0165 - accuracy: 0.9962 - val_loss: 0.1587 - val_accuracy: 0.9840\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0154 - accuracy: 0.9962 - val_loss: 0.1544 - val_accuracy: 0.9848\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.1596 - val_accuracy: 0.9827\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.1643 - val_accuracy: 0.9842\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0143 - accuracy: 0.9964 - val_loss: 0.1606 - val_accuracy: 0.9840\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.1529 - val_accuracy: 0.9850\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0149 - accuracy: 0.9970 - val_loss: 0.1976 - val_accuracy: 0.9830\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0143 - accuracy: 0.9968 - val_loss: 0.1739 - val_accuracy: 0.9836\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0135 - accuracy: 0.9972 - val_loss: 0.1731 - val_accuracy: 0.9829\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0159 - accuracy: 0.9965 - val_loss: 0.1816 - val_accuracy: 0.9838\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.1924 - val_accuracy: 0.9834\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.1716 - val_accuracy: 0.9841\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.1764 - val_accuracy: 0.9839\n",
      "Test loss: 0.17644493281841278\n",
      "Test accuracy: 0.9839000105857849\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.2475 - accuracy: 0.9250 - val_loss: 0.1110 - val_accuracy: 0.9665\n",
      "Epoch 2/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1037 - accuracy: 0.9688 - val_loss: 0.0889 - val_accuracy: 0.9714\n",
      "Epoch 3/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0748 - accuracy: 0.9768 - val_loss: 0.0810 - val_accuracy: 0.9772\n",
      "Epoch 4/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0627 - accuracy: 0.9822 - val_loss: 0.0814 - val_accuracy: 0.9785\n",
      "Epoch 5/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0486 - accuracy: 0.9852 - val_loss: 0.0686 - val_accuracy: 0.9821\n",
      "Epoch 6/80\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0437 - accuracy: 0.9862 - val_loss: 0.0949 - val_accuracy: 0.9777\n",
      "Epoch 7/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0394 - accuracy: 0.9883 - val_loss: 0.0765 - val_accuracy: 0.9810\n",
      "Epoch 8/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0348 - accuracy: 0.9901 - val_loss: 0.0906 - val_accuracy: 0.9802\n",
      "Epoch 9/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 0.0846 - val_accuracy: 0.9803\n",
      "Epoch 10/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.0964 - val_accuracy: 0.9816\n",
      "Epoch 11/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0265 - accuracy: 0.9923 - val_loss: 0.0906 - val_accuracy: 0.9827\n",
      "Epoch 12/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0249 - accuracy: 0.9929 - val_loss: 0.1059 - val_accuracy: 0.9806\n",
      "Epoch 13/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0251 - accuracy: 0.9929 - val_loss: 0.0960 - val_accuracy: 0.9835\n",
      "Epoch 14/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.1063 - val_accuracy: 0.9830\n",
      "Epoch 15/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 0.1045 - val_accuracy: 0.9855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.1237 - val_accuracy: 0.9831\n",
      "Epoch 17/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0195 - accuracy: 0.9948 - val_loss: 0.1176 - val_accuracy: 0.9820\n",
      "Epoch 18/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0203 - accuracy: 0.9944 - val_loss: 0.1085 - val_accuracy: 0.9846\n",
      "Epoch 19/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0177 - accuracy: 0.9954 - val_loss: 0.1293 - val_accuracy: 0.9811\n",
      "Epoch 20/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0184 - accuracy: 0.9954 - val_loss: 0.1494 - val_accuracy: 0.9824\n",
      "Epoch 21/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0147 - accuracy: 0.9959 - val_loss: 0.1414 - val_accuracy: 0.9827\n",
      "Epoch 22/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.1225 - val_accuracy: 0.9841\n",
      "Epoch 23/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 0.1394 - val_accuracy: 0.9823\n",
      "Epoch 24/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0154 - accuracy: 0.9961 - val_loss: 0.1312 - val_accuracy: 0.9824\n",
      "Epoch 25/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0149 - accuracy: 0.9965 - val_loss: 0.1508 - val_accuracy: 0.9832\n",
      "Epoch 26/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.1442 - val_accuracy: 0.9824\n",
      "Epoch 27/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.1567 - val_accuracy: 0.9838\n",
      "Epoch 28/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.1590 - val_accuracy: 0.9831\n",
      "Epoch 29/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0154 - accuracy: 0.9965 - val_loss: 0.1570 - val_accuracy: 0.9836\n",
      "Epoch 30/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.1586 - val_accuracy: 0.9833\n",
      "Epoch 31/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0141 - accuracy: 0.9968 - val_loss: 0.1860 - val_accuracy: 0.9827\n",
      "Epoch 32/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0127 - accuracy: 0.9971 - val_loss: 0.1575 - val_accuracy: 0.9840\n",
      "Epoch 33/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0121 - accuracy: 0.9972 - val_loss: 0.1775 - val_accuracy: 0.9842\n",
      "Epoch 34/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.1690 - val_accuracy: 0.9830\n",
      "Epoch 35/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.1836 - val_accuracy: 0.9844\n",
      "Epoch 36/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.1728 - val_accuracy: 0.9840\n",
      "Epoch 37/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 0.1582 - val_accuracy: 0.9843\n",
      "Epoch 38/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.1850 - val_accuracy: 0.9840\n",
      "Epoch 39/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.1742 - val_accuracy: 0.9824\n",
      "Epoch 40/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 0.1978 - val_accuracy: 0.9829\n",
      "Epoch 41/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0126 - accuracy: 0.9973 - val_loss: 0.1972 - val_accuracy: 0.9834\n",
      "Epoch 42/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.1931 - val_accuracy: 0.9843\n",
      "Epoch 43/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0115 - accuracy: 0.9975 - val_loss: 0.1940 - val_accuracy: 0.9834\n",
      "Epoch 44/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.2075 - val_accuracy: 0.9828\n",
      "Epoch 45/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0119 - accuracy: 0.9976 - val_loss: 0.2136 - val_accuracy: 0.9839\n",
      "Epoch 46/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.2178 - val_accuracy: 0.9829\n",
      "Epoch 47/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.1921 - val_accuracy: 0.9853\n",
      "Epoch 48/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0137 - accuracy: 0.9977 - val_loss: 0.1968 - val_accuracy: 0.9840\n",
      "Epoch 49/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0136 - accuracy: 0.9976 - val_loss: 0.2060 - val_accuracy: 0.9830\n",
      "Epoch 50/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0116 - accuracy: 0.9979 - val_loss: 0.2104 - val_accuracy: 0.9827\n",
      "Epoch 51/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0122 - accuracy: 0.9979 - val_loss: 0.2049 - val_accuracy: 0.9828\n",
      "Epoch 52/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0121 - accuracy: 0.9977 - val_loss: 0.1875 - val_accuracy: 0.9836\n",
      "Epoch 53/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.1865 - val_accuracy: 0.9842\n",
      "Epoch 54/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 0.1991 - val_accuracy: 0.9845\n",
      "Epoch 55/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.2298 - val_accuracy: 0.9828\n",
      "Epoch 56/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0113 - accuracy: 0.9980 - val_loss: 0.2109 - val_accuracy: 0.9848\n",
      "Epoch 57/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 0.2007 - val_accuracy: 0.9838\n",
      "Epoch 58/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 0.2062 - val_accuracy: 0.9847\n",
      "Epoch 59/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.1963 - val_accuracy: 0.9836\n",
      "Epoch 60/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 0.2294 - val_accuracy: 0.9826\n",
      "Epoch 61/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 0.2154 - val_accuracy: 0.9842\n",
      "Epoch 62/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0107 - accuracy: 0.9980 - val_loss: 0.2364 - val_accuracy: 0.9842\n",
      "Epoch 63/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.2139 - val_accuracy: 0.9850\n",
      "Epoch 64/80\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.2012 - val_accuracy: 0.9855\n",
      "Epoch 65/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.2577 - val_accuracy: 0.9833\n",
      "Epoch 66/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 0.2652 - val_accuracy: 0.9836\n",
      "Epoch 67/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.2294 - val_accuracy: 0.9845\n",
      "Epoch 68/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0106 - accuracy: 0.9980 - val_loss: 0.2483 - val_accuracy: 0.9839\n",
      "Epoch 69/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0104 - accuracy: 0.9980 - val_loss: 0.2511 - val_accuracy: 0.9847\n",
      "Epoch 70/80\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0101 - accuracy: 0.9982 - val_loss: 0.2482 - val_accuracy: 0.9843\n",
      "Epoch 71/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 0.2753 - val_accuracy: 0.9827\n",
      "Epoch 72/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.2736 - val_accuracy: 0.9845\n",
      "Epoch 73/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.2537 - val_accuracy: 0.9835\n",
      "Epoch 74/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 0.2727 - val_accuracy: 0.9835\n",
      "Epoch 75/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.2668 - val_accuracy: 0.9834\n",
      "Epoch 76/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.2841 - val_accuracy: 0.9830\n",
      "Epoch 77/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.2568 - val_accuracy: 0.9838\n",
      "Epoch 78/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0112 - accuracy: 0.9983 - val_loss: 0.2311 - val_accuracy: 0.9852\n",
      "Epoch 79/80\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0099 - accuracy: 0.9984 - val_loss: 0.2793 - val_accuracy: 0.9835\n",
      "Epoch 80/80\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.2388 - val_accuracy: 0.9858\n",
      "Test loss: 0.23880162835121155\n",
      "Test accuracy: 0.98580002784729\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2466 - accuracy: 0.9247 - val_loss: 0.0988 - val_accuracy: 0.9674\n",
      "Epoch 2/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1019 - accuracy: 0.9690 - val_loss: 0.0854 - val_accuracy: 0.9742\n",
      "Epoch 3/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0766 - accuracy: 0.9763 - val_loss: 0.0765 - val_accuracy: 0.9769\n",
      "Epoch 4/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0616 - accuracy: 0.9809 - val_loss: 0.0778 - val_accuracy: 0.9782\n",
      "Epoch 5/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0513 - accuracy: 0.9846 - val_loss: 0.0678 - val_accuracy: 0.9818\n",
      "Epoch 6/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0425 - accuracy: 0.9872 - val_loss: 0.0822 - val_accuracy: 0.9805\n",
      "Epoch 7/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0403 - accuracy: 0.9878 - val_loss: 0.0814 - val_accuracy: 0.9814\n",
      "Epoch 8/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0358 - accuracy: 0.9898 - val_loss: 0.0806 - val_accuracy: 0.9828\n",
      "Epoch 9/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0320 - accuracy: 0.9907 - val_loss: 0.0900 - val_accuracy: 0.9828\n",
      "Epoch 10/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 0.0854 - val_accuracy: 0.9823\n",
      "Epoch 11/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0258 - accuracy: 0.9924 - val_loss: 0.0939 - val_accuracy: 0.9828\n",
      "Epoch 12/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0248 - accuracy: 0.9927 - val_loss: 0.0985 - val_accuracy: 0.9818\n",
      "Epoch 13/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0255 - accuracy: 0.9929 - val_loss: 0.0970 - val_accuracy: 0.9823\n",
      "Epoch 14/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.0958 - val_accuracy: 0.9843\n",
      "Epoch 15/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.1169 - val_accuracy: 0.9826\n",
      "Epoch 16/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0208 - accuracy: 0.9945 - val_loss: 0.1193 - val_accuracy: 0.9818\n",
      "Epoch 17/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0191 - accuracy: 0.9949 - val_loss: 0.1048 - val_accuracy: 0.9838\n",
      "Epoch 18/120\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.1068 - val_accuracy: 0.9854\n",
      "Epoch 19/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0210 - accuracy: 0.9946 - val_loss: 0.1301 - val_accuracy: 0.9826\n",
      "Epoch 20/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0180 - accuracy: 0.9954 - val_loss: 0.1180 - val_accuracy: 0.9829\n",
      "Epoch 21/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0167 - accuracy: 0.9955 - val_loss: 0.1300 - val_accuracy: 0.9824\n",
      "Epoch 22/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.1451 - val_accuracy: 0.9821\n",
      "Epoch 23/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0174 - accuracy: 0.9954 - val_loss: 0.1344 - val_accuracy: 0.9828\n",
      "Epoch 24/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.1328 - val_accuracy: 0.9831\n",
      "Epoch 25/120\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.1445 - val_accuracy: 0.9836\n",
      "Epoch 26/120\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0153 - accuracy: 0.9962 - val_loss: 0.1365 - val_accuracy: 0.9848\n",
      "Epoch 27/120\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 0.1602 - val_accuracy: 0.9820\n",
      "Epoch 28/120\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0137 - accuracy: 0.9966 - val_loss: 0.1572 - val_accuracy: 0.9827\n",
      "Epoch 29/120\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.1376 - val_accuracy: 0.9864\n",
      "Epoch 30/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0146 - accuracy: 0.9966 - val_loss: 0.1439 - val_accuracy: 0.9836\n",
      "Epoch 31/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0146 - accuracy: 0.9968 - val_loss: 0.1759 - val_accuracy: 0.9811\n",
      "Epoch 32/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0143 - accuracy: 0.9967 - val_loss: 0.1563 - val_accuracy: 0.9836\n",
      "Epoch 33/120\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.1541 - val_accuracy: 0.9817\n",
      "Epoch 34/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.1572 - val_accuracy: 0.9842\n",
      "Epoch 35/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.1504 - val_accuracy: 0.9828\n",
      "Epoch 36/120\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.1500 - val_accuracy: 0.9852\n",
      "Epoch 37/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 0.1751 - val_accuracy: 0.9827\n",
      "Epoch 38/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0140 - accuracy: 0.9972 - val_loss: 0.1715 - val_accuracy: 0.9839\n",
      "Epoch 39/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.1729 - val_accuracy: 0.9834\n",
      "Epoch 40/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.1918 - val_accuracy: 0.9824\n",
      "Epoch 41/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0145 - accuracy: 0.9973 - val_loss: 0.2027 - val_accuracy: 0.9835\n",
      "Epoch 42/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0117 - accuracy: 0.9975 - val_loss: 0.2009 - val_accuracy: 0.9833\n",
      "Epoch 43/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0150 - accuracy: 0.9970 - val_loss: 0.1946 - val_accuracy: 0.9838\n",
      "Epoch 44/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0146 - accuracy: 0.9971 - val_loss: 0.2149 - val_accuracy: 0.9838\n",
      "Epoch 45/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.1911 - val_accuracy: 0.9828\n",
      "Epoch 46/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 0.2177 - val_accuracy: 0.9823\n",
      "Epoch 47/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0115 - accuracy: 0.9977 - val_loss: 0.2044 - val_accuracy: 0.9845\n",
      "Epoch 48/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0122 - accuracy: 0.9975 - val_loss: 0.1895 - val_accuracy: 0.9827\n",
      "Epoch 49/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0166 - accuracy: 0.9975 - val_loss: 0.1798 - val_accuracy: 0.9851\n",
      "Epoch 50/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 0.1922 - val_accuracy: 0.9837\n",
      "Epoch 51/120\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.2037 - val_accuracy: 0.9841\n",
      "Epoch 52/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0132 - accuracy: 0.9974 - val_loss: 0.2409 - val_accuracy: 0.9812\n",
      "Epoch 53/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 0.1937 - val_accuracy: 0.9836\n",
      "Epoch 54/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0125 - accuracy: 0.9978 - val_loss: 0.2073 - val_accuracy: 0.9853\n",
      "Epoch 55/120\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0135 - accuracy: 0.9976 - val_loss: 0.2090 - val_accuracy: 0.9843\n",
      "Epoch 56/120\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.2094 - val_accuracy: 0.9847\n",
      "Epoch 57/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 0.2048 - val_accuracy: 0.9840\n",
      "Epoch 58/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0094 - accuracy: 0.9984 - val_loss: 0.2219 - val_accuracy: 0.9838\n",
      "Epoch 59/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.2197 - val_accuracy: 0.9835\n",
      "Epoch 60/120\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.2448 - val_accuracy: 0.9821\n",
      "Epoch 61/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0125 - accuracy: 0.9979 - val_loss: 0.2393 - val_accuracy: 0.9830\n",
      "Epoch 62/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0121 - accuracy: 0.9978 - val_loss: 0.2156 - val_accuracy: 0.9843\n",
      "Epoch 63/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0111 - accuracy: 0.9977 - val_loss: 0.2259 - val_accuracy: 0.9844\n",
      "Epoch 64/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0113 - accuracy: 0.9980 - val_loss: 0.2142 - val_accuracy: 0.9846\n",
      "Epoch 65/120\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0109 - accuracy: 0.9980 - val_loss: 0.2328 - val_accuracy: 0.9846\n",
      "Epoch 66/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0113 - accuracy: 0.9980 - val_loss: 0.2262 - val_accuracy: 0.9827\n",
      "Epoch 67/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0121 - accuracy: 0.9981 - val_loss: 0.2255 - val_accuracy: 0.9830\n",
      "Epoch 68/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0093 - accuracy: 0.9981 - val_loss: 0.2472 - val_accuracy: 0.9822\n",
      "Epoch 69/120\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0112 - accuracy: 0.9982 - val_loss: 0.2493 - val_accuracy: 0.9844\n",
      "Epoch 70/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.2250 - val_accuracy: 0.9841\n",
      "Epoch 71/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0104 - accuracy: 0.9984 - val_loss: 0.2403 - val_accuracy: 0.9834\n",
      "Epoch 72/120\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0102 - accuracy: 0.9984 - val_loss: 0.2393 - val_accuracy: 0.9835\n",
      "Epoch 73/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0108 - accuracy: 0.9981 - val_loss: 0.2206 - val_accuracy: 0.9833\n",
      "Epoch 74/120\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0102 - accuracy: 0.9981 - val_loss: 0.2498 - val_accuracy: 0.9841\n",
      "Epoch 75/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.2641 - val_accuracy: 0.9825\n",
      "Epoch 76/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 0.2672 - val_accuracy: 0.9823\n",
      "Epoch 77/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.2337 - val_accuracy: 0.9827\n",
      "Epoch 78/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0114 - accuracy: 0.9980 - val_loss: 0.2312 - val_accuracy: 0.9852\n",
      "Epoch 79/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.2515 - val_accuracy: 0.9830\n",
      "Epoch 80/120\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.2572 - val_accuracy: 0.9832\n",
      "Epoch 81/120\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.2882 - val_accuracy: 0.9825\n",
      "Epoch 82/120\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0106 - accuracy: 0.9984 - val_loss: 0.2623 - val_accuracy: 0.9848\n",
      "Epoch 83/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0113 - accuracy: 0.9981 - val_loss: 0.2795 - val_accuracy: 0.9845\n",
      "Epoch 84/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0116 - accuracy: 0.9982 - val_loss: 0.2475 - val_accuracy: 0.9849\n",
      "Epoch 85/120\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0135 - accuracy: 0.9979 - val_loss: 0.2522 - val_accuracy: 0.9844\n",
      "Epoch 86/120\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0093 - accuracy: 0.9981 - val_loss: 0.2689 - val_accuracy: 0.9832\n",
      "Epoch 87/120\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0093 - accuracy: 0.9984 - val_loss: 0.2982 - val_accuracy: 0.9828\n",
      "Epoch 88/120\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0117 - accuracy: 0.9984 - val_loss: 0.2559 - val_accuracy: 0.9845\n",
      "Epoch 89/120\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0100 - accuracy: 0.9984 - val_loss: 0.2888 - val_accuracy: 0.9836\n",
      "Epoch 90/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.2891 - val_accuracy: 0.9828\n",
      "Epoch 91/120\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.2978 - val_accuracy: 0.9834\n",
      "Epoch 92/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0115 - accuracy: 0.9984 - val_loss: 0.2972 - val_accuracy: 0.9835\n",
      "Epoch 93/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0099 - accuracy: 0.9984 - val_loss: 0.2813 - val_accuracy: 0.9844\n",
      "Epoch 94/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0125 - accuracy: 0.9980 - val_loss: 0.2994 - val_accuracy: 0.9840\n",
      "Epoch 95/120\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.2857 - val_accuracy: 0.9839\n",
      "Epoch 96/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 0.2759 - val_accuracy: 0.9840\n",
      "Epoch 97/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0102 - accuracy: 0.9984 - val_loss: 0.2554 - val_accuracy: 0.9846\n",
      "Epoch 98/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.3379 - val_accuracy: 0.9817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0101 - accuracy: 0.9984 - val_loss: 0.3197 - val_accuracy: 0.9834\n",
      "Epoch 100/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0129 - accuracy: 0.9980 - val_loss: 0.2951 - val_accuracy: 0.9829\n",
      "Epoch 101/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.2663 - val_accuracy: 0.9849\n",
      "Epoch 102/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0112 - accuracy: 0.9983 - val_loss: 0.2931 - val_accuracy: 0.9832\n",
      "Epoch 103/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 0.3114 - val_accuracy: 0.9839\n",
      "Epoch 104/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.3320 - val_accuracy: 0.9834\n",
      "Epoch 105/120\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0097 - accuracy: 0.9984 - val_loss: 0.3330 - val_accuracy: 0.9841\n",
      "Epoch 106/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0097 - accuracy: 0.9985 - val_loss: 0.3186 - val_accuracy: 0.9833\n",
      "Epoch 107/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0119 - accuracy: 0.9983 - val_loss: 0.3214 - val_accuracy: 0.9831\n",
      "Epoch 108/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0128 - accuracy: 0.9982 - val_loss: 0.2831 - val_accuracy: 0.9837\n",
      "Epoch 109/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0089 - accuracy: 0.9986 - val_loss: 0.2981 - val_accuracy: 0.9840\n",
      "Epoch 110/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0117 - accuracy: 0.9985 - val_loss: 0.3024 - val_accuracy: 0.9844\n",
      "Epoch 111/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0122 - accuracy: 0.9980 - val_loss: 0.2944 - val_accuracy: 0.9842\n",
      "Epoch 112/120\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0120 - accuracy: 0.9982 - val_loss: 0.3159 - val_accuracy: 0.9834\n",
      "Epoch 113/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.3155 - val_accuracy: 0.9833\n",
      "Epoch 114/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0132 - accuracy: 0.9984 - val_loss: 0.3242 - val_accuracy: 0.9826\n",
      "Epoch 115/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 0.2937 - val_accuracy: 0.9836\n",
      "Epoch 116/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0127 - accuracy: 0.9984 - val_loss: 0.3381 - val_accuracy: 0.9814\n",
      "Epoch 117/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0090 - accuracy: 0.9987 - val_loss: 0.3075 - val_accuracy: 0.9831\n",
      "Epoch 118/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0113 - accuracy: 0.9984 - val_loss: 0.3118 - val_accuracy: 0.9847\n",
      "Epoch 119/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0099 - accuracy: 0.9984 - val_loss: 0.3394 - val_accuracy: 0.9839\n",
      "Epoch 120/120\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0110 - accuracy: 0.9984 - val_loss: 0.3239 - val_accuracy: 0.9849\n",
      "Test loss: 0.3239193856716156\n",
      "Test accuracy: 0.9848999977111816\n"
     ]
    }
   ],
   "source": [
    "# define the model and evaluate without noise and different epochs\n",
    "epochs = [10, 20, 40, 80, 120]\n",
    "\n",
    "for epoch in epochs:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epoch,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.07930032908916473, 0.9825000166893005],\n",
       " [0.148671954870224, 0.9825999736785889],\n",
       " [0.17644493281841278, 0.9839000105857849],\n",
       " [0.23880162835121155, 0.98580002784729],\n",
       " [0.3239193856716156, 0.9848999977111816]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 1.3363 - accuracy: 0.5509 - val_loss: 0.5976 - val_accuracy: 0.8051\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.7162 - accuracy: 0.7644 - val_loss: 0.4632 - val_accuracy: 0.8486\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.5502 - accuracy: 0.8202 - val_loss: 0.5271 - val_accuracy: 0.8213\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4676 - accuracy: 0.8508 - val_loss: 0.4114 - val_accuracy: 0.8671\n",
      "Epoch 5/10\n",
      "362/469 [======================>.......] - ETA: 0s - loss: 0.4073 - accuracy: 0.8694"
     ]
    }
   ],
   "source": [
    "# add different noise scales\n",
    "scales = [.1, .5, 1.0, 2.0, 4.0]\n",
    "\n",
    "for epoch in epochs:\n",
    "    \n",
    "    # build model and evaluate\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "\n",
    "    for scale in scales:\n",
    "        print(epoch)\n",
    "        \n",
    "        x = random.normal(loc=1, scale=scale, size=x_train.shape)\n",
    "        x_train = x_train + x\n",
    "        \n",
    "        x = random.normal(loc=1, scale=scale, size=x_test.shape)\n",
    "        x_test = x_test + x\n",
    "        \n",
    "        history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "        \n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        \n",
    "        scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
